{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c344e831-873a-40ae-b206-30a54a43d036",
   "metadata": {},
   "source": [
    "# ワークロードを Claude 3.7 に移行する\n",
    "\n",
    "このノートブックでは、新しい拡張思考機能の活用に重点を置き、既存のプロンプトとワークフローを Claude 3.5 Sonnet から Claude 3.7 に効果的に移行する方法を説明します。学習内容:\n",
    "\n",
    "1. 拡張思考のメリットが得られるプロンプトを特定する方法\n",
    "2. 思考の連鎖プロンプトをリファクタリングする手法\n",
    "3. プロンプトを簡素化するためのベスト プラクティス\n",
    "4. パフォーマンス比較による前後の例\n",
    "\n",
    "## 前提条件\n",
    "- Claude 3.5 Sonnet の機能に関する理解\n",
    "- 思考の連鎖プロンプトに関する知識\n",
    "- Python と Bedrock API に関する知識\n",
    "- 以前のレッスン (特に拡張思考に関するレッスン 1 ～ 2) を完了していること\n",
    "\n",
    "まず、環境を設定して必要なライブラリをインポートしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f93836-b22b-410e-9742-8026b022956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Import our utility functions from previous lessons\n",
    "import claude_utils\n",
    "\n",
    "# Set up the Bedrock clients using our utility module\n",
    "REGION = 'us-west-2'  # Change to your preferred region\n",
    "bedrock, bedrock_runtime = claude_utils.create_bedrock_clients(REGION)\n",
    "\n",
    "# Define model IDs for comparison\n",
    "CLAUDE_35_SONNET_MODEL_ID = 'us.anthropic.claude-3-5-sonnet-20241022-v2:0'\n",
    "CLAUDE_37_SONNET_MODEL_ID = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "\n",
    "# Verify model availability\n",
    "claude_utils.verify_model_availability(bedrock, CLAUDE_37_SONNET_MODEL_ID)\n",
    "claude_utils.verify_model_availability(bedrock, CLAUDE_35_SONNET_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b6d90-1126-4557-b4cb-02984feb5aa9",
   "metadata": {},
   "source": [
    "## 移行のタイミングを理解する\n",
    "\n",
    "特定の移行手法について詳しく説明する前に、どのプロンプトが Claude 3.7 の拡張思考機能への移行に適しているかを理解することが重要です。\n",
    "\n",
    "### 移行に適した候補:\n",
    "- 明示的な思考の連鎖指示を使用するプロンプト\n",
    "- 1024 トークンを超える思考を必要とする複雑な推論タスク\n",
    "- 複数ステップの問題解決ワークフロー\n",
    "- 体系的な分析のメリットがあるタスク\n",
    "\n",
    "### 移行にあまり適さないもの:\n",
    "- 単純な事実のクエリ\n",
    "- 基本的なコンテンツ生成\n",
    "- 詳細な推論を必要としないタスク\n",
    "- 標準プロンプトですでに適切に機能しているワークフロー\n",
    "\n",
    "これらの違いを理解するために、具体的な例をいくつか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51539ca-78e8-4296-8a47-b67261b8acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(prompt, chain_of_thought=True, reasoning_budget=4096):\n",
    "    \"\"\"\n",
    "    Compare responses between Claude 3.5 with chain-of-thought and Claude 3.7 with extended thinking\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The base prompt to test\n",
    "        chain_of_thought (bool): Whether to add chain-of-thought instructions for 3.5\n",
    "        reasoning_budget (int): Token budget for 3.7's extended thinking\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (Claude 3.5 response, Claude 3.7 response)\n",
    "    \"\"\"\n",
    "    # Create 3.5 prompt with optional chain-of-thought\n",
    "    if chain_of_thought:\n",
    "        cot_prompt = f\"\"\"\n",
    "        Let's solve this step by step:\n",
    "        1. First, carefully analyze what's being asked\n",
    "        2. Break down the problem into parts\n",
    "        3. Solve each part methodically\n",
    "        4. Combine the results for a final answer\n",
    "\n",
    "        {prompt}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        cot_prompt = prompt\n",
    "    \n",
    "    # Get 3.5 response\n",
    "    response_35 = claude_utils.invoke_claude(\n",
    "        bedrock_runtime,\n",
    "        cot_prompt,\n",
    "        CLAUDE_35_SONNET_MODEL_ID,\n",
    "        enable_reasoning=False,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Get 3.7 response with extended thinking\n",
    "    response_37 = claude_utils.invoke_claude(\n",
    "        bedrock_runtime,\n",
    "        prompt,  # Note: No CoT instructions needed\n",
    "        CLAUDE_37_SONNET_MODEL_ID,\n",
    "        enable_reasoning=True,\n",
    "        reasoning_budget=reasoning_budget,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    return response_35, response_37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b790e0-2f4b-4fd0-becd-47ce3a43912f",
   "metadata": {},
   "source": [
    "## 例 1: 数学の問題解決\n",
    "\n",
    "まずは典型的な例から始めましょう。従来は思考の連鎖を促す手法を使用していた数学の文章問題です。このタイプの問題は、次のような理由から移行に最適です。\n",
    "- 構造化された推論が必要\n",
    "- 中間ステップを示すことでメリットが得られる\n",
    "- 多くの場合、複数の計算が必要\n",
    "- 中間結果の検証が必要\n",
    "\n",
    "この問題が Claude 3.5 でどのように処理されたかと、Claude 3.7 の拡張思考でよりエレガントに解決できる方法を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce7d7b-5ead-409f-9224-c080810ae786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional math word problem\n",
    "math_problem = \"\"\"\n",
    "A store is having a 30% off sale. A customer buys three items:\n",
    "- A jacket originally priced at $120\n",
    "- A pair of shoes originally priced at $85\n",
    "- A shirt originally priced at $45\n",
    "\n",
    "If there is an additional 10% discount for spending over $200 (calculated after the 30% sale discount),\n",
    "how much does the customer save in total, and what is their final cost?\n",
    "\n",
    "Show all calculations clearly.\n",
    "\"\"\"\n",
    "\n",
    "# Compare the models' responses\n",
    "response_35, response_37 = compare_models(\n",
    "    math_problem,\n",
    "    chain_of_thought=True,  # Enable CoT for 3.5\n",
    "    reasoning_budget=2048   # Moderate budget for this problem\n",
    ")\n",
    "\n",
    "# Display responses for comparison\n",
    "print(\"Claude 3.5 Response (with chain-of-thought):\")\n",
    "print(\"-\" * 80)\n",
    "claude_utils.display_claude_response(response_35)\n",
    "\n",
    "print(\"\\nClaude 3.7 Response (with extended thinking):\")\n",
    "print(\"-\" * 80)\n",
    "claude_utils.display_claude_response(response_37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830f2a0-8ad7-4591-8c4d-7254d65b503e",
   "metadata": {},
   "source": [
    "### 回答の主な違い\n",
    "\n",
    "2 つのモデルがこの問題にどのようにアプローチしたかを分析してみましょう。\n",
    "\n",
    "1. **プロンプト構造**\n",
    "- Claude 3.5 では、明示的なステップバイステップの指示が必要でした\n",
    "- Claude 3.7 では、独自の推論アプローチを開発しました\n",
    "\n",
    "2. **回答の品質**\n",
    "- 計算の完全性\n",
    "- 説明の明確さ\n",
    "- 結果の検証\n",
    "\n",
    "3. **トークンの効率**\n",
    "- プロンプトの長さの比較\n",
    "- 回答の長さの比較\n",
    "- 全体的なトークンの使用\n",
    "\n",
    "これらの違いは、数学的推論タスクにおいて、従来の思考の連鎖プロンプトよりも拡張思考の方が効果的である理由を強調しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0686ead-c737-4407-a68e-502c7cb0f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison_metrics(response_35, response_37):\n",
    "    \"\"\"\n",
    "    Display detailed comparison metrics between the two responses\n",
    "    \"\"\"\n",
    "    # Calculate metrics for 3.5\n",
    "    tokens_35 = response_35.get('usage', {}).get('totalTokens', 0)\n",
    "    time_35 = response_35.get('_elapsed_time', 0)\n",
    "    \n",
    "    # Calculate metrics for 3.7\n",
    "    tokens_37 = response_37.get('usage', {}).get('totalTokens', 0)\n",
    "    time_37 = response_37.get('_elapsed_time', 0)\n",
    "    \n",
    "    # Display comparison\n",
    "    print(\"Performance Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Claude 3.5 (with CoT):\")\n",
    "    print(f\"- Total tokens: {tokens_35:,}\")\n",
    "    print(f\"- Response time: {time_35:.2f} seconds\")\n",
    "    print(f\"- Tokens per second: {tokens_35/time_35:.1f}\")\n",
    "    print(\"\\nClaude 3.7 (with extended thinking):\")\n",
    "    print(f\"- Total tokens: {tokens_37:,}\")\n",
    "    print(f\"- Response time: {time_37:.2f} seconds\")\n",
    "    print(f\"- Tokens per second: {tokens_37/time_37:.1f}\")\n",
    "    \n",
    "    # Calculate efficiency gains/losses\n",
    "    token_diff = ((tokens_37 - tokens_35) / tokens_35) * 100\n",
    "    time_diff = ((time_37 - time_35) / time_35) * 100\n",
    "    \n",
    "    print(\"\\nEfficiency Comparison:\")\n",
    "    print(f\"Token usage change: {token_diff:+.1f}%\")\n",
    "    print(f\"Response time change: {time_diff:+.1f}%\")\n",
    "\n",
    "# Display metrics for our math problem example\n",
    "display_comparison_metrics(response_35, response_37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffd1dc-4f1d-4c2c-a767-f5168e31cff2",
   "metadata": {},
   "source": [
    "## 例 2: 分析と推奨事項\n",
    "\n",
    "2 番目の例では、情報を統合して推奨事項を作成する必要がある、より複雑な分析タスクを見てみましょう。このタイプのプロンプトでは、思考の連鎖がよく使用され、次のことが実現されます。\n",
    "- 分析プロセスの構造化\n",
    "- 複数の要因の考慮の確保\n",
    "- 推奨事項の開発のガイド\n",
    "- 論理的な流れの維持\n",
    "\n",
    "この例では、Claude 3.7 の拡張思考が、規定された思考の連鎖の手順よりも自然に複雑な分析を処理できることを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857c2c8-ce61-4113-bb39-e744d263d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex analysis problem\n",
    "analysis_prompt = \"\"\"\n",
    "Analyze the potential impact of implementing a four-day work week at a software company with 500 employees.\n",
    "\n",
    "Consider:\n",
    "- Employee productivity and satisfaction\n",
    "- Project timelines and deadlines\n",
    "- Customer support availability\n",
    "- Operating costs and profitability\n",
    "- Team coordination and meetings\n",
    "- Industry competitiveness\n",
    "\n",
    "Provide specific recommendations for successfully implementing this change.\n",
    "\"\"\"\n",
    "\n",
    "# Compare the models' responses\n",
    "response_35, response_37 = compare_models(\n",
    "    analysis_prompt,\n",
    "    chain_of_thought=True,     # Enable CoT for 3.5\n",
    "    reasoning_budget=4096      # Larger budget for complex analysis\n",
    ")\n",
    "\n",
    "# Display responses for comparison\n",
    "print(\"Claude 3.5 Response (with chain-of-thought):\")\n",
    "print(\"-\" * 80)\n",
    "claude_utils.display_claude_response(response_35)\n",
    "\n",
    "print(\"\\nClaude 3.7 Response (with extended thinking):\")\n",
    "print(\"-\" * 80)\n",
    "claude_utils.display_claude_response(response_37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d39d9-e175-489f-be3b-41992dbd14bc",
   "metadata": {},
   "source": [
    "### 移行パターン: 構造化された推論から自然な推論へ\n",
    "\n",
    "この例は、Claude 3.5 から 3.7 への移行における重要なパターンを示しています:\n",
    "\n",
    "1. **従来の思考の連鎖パターン**\n",
    "- 明示的な分析手順が必要\n",
    "- 構造的なガイダンスが必要\n",
    "- 多くの場合、定型的な応答が発生\n",
    "\n",
    "2. **拡張思考パターン**\n",
    "- 自然な推論フローを開発\n",
    "- 複数の視点を有機的に統合\n",
    "- より微妙な分析を生成\n",
    "\n",
    "### 移行の主な利点\n",
    "- より包括的な分析\n",
    "- 関連要因のより優れた統合\n",
    "- より自然なアイデアの流れ\n",
    "- より強力で、より文脈的な推奨事項\n",
    "\n",
    "このパターンは、厳格な構造によって洞察の開発が制限される可能性がある複雑な分析タスクに特に役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697205a-9b6e-4f27-8d26-afdc1d59ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_response_patterns(response_35, response_37):\n",
    "    \"\"\"\n",
    "    Analyze response patterns between Claude 3.5 and 3.7\n",
    "    \n",
    "    Args:\n",
    "        response_35 (dict): Response from Claude 3.5\n",
    "        response_37 (dict): Response from Claude 3.7\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints analysis to stdout\n",
    "    \"\"\"\n",
    "    # Safely extract responses with error handling\n",
    "    text_35 = claude_utils.extract_response_content(response_35) or \"\"\n",
    "    text_37 = claude_utils.extract_response_content(response_37) or \"\"\n",
    "    \n",
    "    if not text_35 or not text_37:\n",
    "        print(\"Error: One or both responses are empty\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Analyze structure\n",
    "        sections_35 = len([l for l in text_35.split('\\n') if l.strip().startswith('#')])\n",
    "        sections_37 = len([l for l in text_37.split('\\n') if l.strip().startswith('#')])\n",
    "        \n",
    "        bullets_35 = len([l for l in text_35.split('\\n') if l.strip().startswith('-')])\n",
    "        bullets_37 = len([l for l in text_37.split('\\n') if l.strip().startswith('-')])\n",
    "        \n",
    "        # Calculate paragraphs safely\n",
    "        paragraphs_35 = len([p for p in text_35.split('\\n\\n') if p.strip()])\n",
    "        paragraphs_37 = len([p for p in text_37.split('\\n\\n') if p.strip()])\n",
    "        \n",
    "        # Calculate words safely\n",
    "        words_35 = len(text_35.split())\n",
    "        words_37 = len(text_37.split())\n",
    "        \n",
    "        # Display analysis\n",
    "        print(\"Response Pattern Analysis:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"Claude 3.5 Structure:\")\n",
    "        print(f\"- Main sections: {sections_35}\")\n",
    "        print(f\"- Bullet points: {bullets_35}\")\n",
    "        print(f\"- Average words per paragraph: {words_35/max(1, paragraphs_35):.1f}\")\n",
    "        print(f\"- Claude 3.5 v2 Response: \\n\\n{text_35}\")\n",
    "        \n",
    "        print(\"\\nClaude 3.7 Structure:\")\n",
    "        print(f\"- Main sections: {sections_37}\")\n",
    "        print(f\"- Bullet points: {bullets_37}\")\n",
    "        print(f\"- Average words per paragraph: {words_37/max(1, paragraphs_37):.1f}\")\n",
    "        print(f\"- Claude 3.7 Response: \\n\\n{text_37}\")\n",
    "        \n",
    "        # Analyze differences in approach\n",
    "        print(\"\\nKey Differences:\")\n",
    "        print(f\"- Section organization: {'More' if sections_37 > sections_35 else 'Less'} structured\")\n",
    "        print(f\"- Point presentation: {'More' if bullets_37 > bullets_35 else 'Less'} bullet points\")\n",
    "        print(f\"- Writing style: {'More' if words_37 > words_35 else 'Less'} detailed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing responses: {str(e)}\")\n",
    "\n",
    "# Analyze patterns in our analysis example\n",
    "analyze_response_patterns(response_35, response_37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9375f-87dd-4d41-8b32-48968d7bb355",
   "metadata": {},
   "source": [
    "## プロンプト移行のベスト プラクティス\n",
    "\n",
    "プロンプトを Claude 3.5 から Claude 3.7 に移行する場合、移行を成功させるには、いくつかの重要なプラクティスが役立ちます。\n",
    "\n",
    "### 1. 不要な構造を削除する\n",
    "- 明示的なステップバイステップの指示を排除する\n",
    "- 人工的な思考マーカーを削除する\n",
    "- 拡張思考が自然な流れを生み出すようにする\n",
    "\n",
    "### 2. トークン バジェットを調整する\n",
    "- 拡張思考用に最小 1024 トークンから開始する\n",
    "- タスクの複雑さに基づいてバジェットをスケールする\n",
    "- 結果に基づいて監視および最適化する\n",
    "\n",
    "### 3. 明確な要件に焦点を当てる\n",
    "- 目的を明確に述べる\n",
    "- 制約を直接指定する\n",
    "- 関連するコンテキストを提供する\n",
    "\n",
    "体系的な例を使用して、これらのプラクティスを調べてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3e3e5-ee99-4b1d-9f81-c3c77a8f485c",
   "metadata": {},
   "source": [
    "#### プロンプト移行ヘルパー:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e59ef8-f5cb-438a-b150-359538c813e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_prompt_migration(original_prompt, verbose=True):\n",
    "    \"\"\"\n",
    "    Use Claude 3.7 to migrate a prompt from chain-of-thought style to extended thinking style\n",
    "    \n",
    "    Args:\n",
    "        original_prompt (str): Original chain-of-thought style prompt\n",
    "        verbose (bool): Whether to show detailed transformation steps\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (original prompt, migrated prompt)\n",
    "    \"\"\"\n",
    "    # Create a prompt for Claude to handle the migration\n",
    "    migration_request = f\"\"\"\n",
    "    Help me migrate this prompt from a chain-of-thought style (used with Claude 3.5) to a cleaner style for Claude 3.7's extended thinking.\n",
    "\n",
    "    Original prompt:\n",
    "    {original_prompt}\n",
    "\n",
    "    Guidelines for migration:\n",
    "    - Remove explicit step-by-step instructions\n",
    "    - Remove artificial thinking markers\n",
    "    - Remove any model-specific steering language for example, instructions about laziness or verbosity\n",
    "    - Remove chain-of-thought guidance and logic\n",
    "    - Preserve important context and requirements\n",
    "    - Make the prompt more natural and direct\n",
    "    - Keep the core question/request clear\n",
    "    \n",
    "    Please provide only the migrated prompt with no additional explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get Claude's migration suggestion\n",
    "    response = claude_utils.invoke_claude(\n",
    "        bedrock_runtime,\n",
    "        migration_request,\n",
    "        CLAUDE_37_SONNET_MODEL_ID,\n",
    "        enable_reasoning=True,\n",
    "        reasoning_budget=2048,  # Moderate budget for this task\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Extract the migrated prompt\n",
    "    migrated_prompt = claude_utils.extract_response_content(response)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Original Prompt:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(original_prompt)\n",
    "        print(\"\\nMigrated Prompt:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(migrated_prompt)\n",
    "        \n",
    "    return original_prompt, migrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0043a75-52f0-4f09-b831-0895978f83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a typical chain-of-thought prompt\n",
    "original_prompt = \"\"\"\n",
    "Let's solve this complex optimization problem step by step:\n",
    "\n",
    "You are planning a conference with the following constraints:\n",
    "1. First, determine the venue capacity needed for 300 attendees\n",
    "2. Then, calculate the budget including:\n",
    "   - Venue rental ($5000/day)\n",
    "   - Catering ($75/person/day)\n",
    "   - Equipment rental ($2000/day)\n",
    "3. Next, optimize the schedule for:\n",
    "   - 3 parallel tracks\n",
    "   - 45-minute sessions\n",
    "   - 15-minute breaks\n",
    "4. Finally, recommend the optimal conference duration in days\n",
    "\n",
    "Think carefully about each step before providing recommendations.\n",
    "\"\"\"\n",
    "\n",
    "# Demonstrate migration\n",
    "orig, migrated = demonstrate_prompt_migration(original_prompt)\n",
    "\n",
    "# Test both versions\n",
    "print(\"\\nTesting both versions:\")\n",
    "response_35, response_37 = compare_models(\n",
    "    migrated,  # Use migrated prompt for both to compare approaches\n",
    "    chain_of_thought=True,  # 3.5 gets CoT instructions\n",
    "    reasoning_budget=4096   # 3.7 gets extended thinking\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(\"\\nResults Comparison:\")\n",
    "display_comparison_metrics(response_35, response_37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7c0af-435b-41a3-ac57-6788d51a2489",
   "metadata": {},
   "source": [
    "## 体系的な移行パターン\n",
    "\n",
    "例に基づいて、プロンプトを Claude 3.5 から Claude 3.7 に移行する際の一般的なパターンをいくつか特定できます。\n",
    "\n",
    "### パターン 1: ステップバイステップから目標指向へ\n",
    "- **前**: 明示的な指示による詳細なステップ シーケンス\n",
    "- **後**: 関連する制約とコンテキストによる明確な目標ステートメント\n",
    "\n",
    "### パターン 2: 明示的推論から暗黙的推論へ\n",
    "- **前**: 「X、Y、Z の考慮事項について考える」\n",
    "- **後**: 「次の要素を考慮する: X、Y、Z」\n",
    "\n",
    "### パターン 3: 構造化された出力から自然な出力へ\n",
    "- **前**: 「セクション A、B、C で応答をフォーマットする」\n",
    "- **後**: 「応答に A、B、C に関する情報を含める」\n",
    "\n",
    "より多くの例を使用して、これらのパターンを実際に確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2350b7d-dd45-4ec6-9dcd-25f721c8e086",
   "metadata": {},
   "source": [
    "## チェックイン ポイント: プロンプト移行の原則\n",
    "\n",
    "プロンプトの移行について学んだことを確認してみましょう。\n",
    "\n",
    "1. **構造の変更**\n",
    "- どのような種類の指示マーカーを安全に削除できますか?\n",
    "- 移行後にプロンプ​​トの長さはどのように変わりますか?\n",
    "- どの要素を保持する必要がありますか?\n",
    "\n",
    "2. **パフォーマンスへの影響**\n",
    "- トークンの使用状況を比較するとどうなりますか?\n",
    "- 応答時間の違いは?\n",
    "- 応答品質は向上しますか?\n",
    "\n",
    "3. **ベスト プラクティス**\n",
    "- いつ構造を保持する必要がありますか?\n",
    "- 適切な推論予算をどのように選択しますか?\n",
    "- プロンプト移行を成功させる要因は何ですか?\n",
    "\n",
    "これらの洞察は、独自のプロンプト移行の取り組みを導くのに役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acacd23-fe54-42f0-848a-3f179556075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define examples of different migration patterns\n",
    "migration_examples = {\n",
    "    \"step_by_step\": {\n",
    "        \"before\": \"\"\"\n",
    "        Let's solve this math problem step by step:\n",
    "        1. First, calculate the total cost before discount\n",
    "        2. Then, apply the 15% discount\n",
    "        3. Next, add 8% sales tax\n",
    "        4. Finally, determine the final price\n",
    "        \n",
    "        How much would a $120 item cost after discount and tax?\n",
    "        \"\"\",\n",
    "        \"complexity\": \"simple\"\n",
    "    },\n",
    "    \n",
    "    \"explicit_reasoning\": {\n",
    "        \"before\": \"\"\"\n",
    "        Think through the implications of remote work by considering:\n",
    "        First, analyze productivity impacts.\n",
    "        Then, examine employee satisfaction effects.\n",
    "        Next, evaluate communication challenges.\n",
    "        Finally, weigh cost savings against potential drawbacks.\n",
    "        \n",
    "        Is remote work a net positive for most organizations?\n",
    "        \"\"\",\n",
    "        \"complexity\": \"medium\"\n",
    "    },\n",
    "    \n",
    "    \"structured_output\": {\n",
    "        \"before\": \"\"\"\n",
    "        Analyze this short story following these steps:\n",
    "        1. First, summarize the plot\n",
    "        2. Then, identify the main themes\n",
    "        3. Next, analyze the character development\n",
    "        4. Finally, discuss the author's writing style\n",
    "        \n",
    "        Structure your analysis with clear sections for each aspect.\n",
    "        \"\"\",\n",
    "        \"complexity\": \"complex\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Migrate and display each example\n",
    "for pattern_name, example in migration_examples.items():\n",
    "    print(f\"\\n\\n{'='*80}\\nMigration Pattern: {pattern_name.replace('_', ' ').title()}\")\n",
    "    print(f\"Complexity: {example['complexity'].title()}\")\n",
    "    \n",
    "    # Migrate the prompt\n",
    "    _, migrated = demonstrate_prompt_migration(example[\"before\"], verbose=False)\n",
    "    \n",
    "    # Display before/after\n",
    "    print(\"\\nBefore:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(example[\"before\"])\n",
    "    \n",
    "    print(\"\\nAfter:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(migrated)\n",
    "    \n",
    "    # Determine appropriate budget based on complexity\n",
    "    budget_map = {\"simple\": 1024, \"medium\": 2048, \"complex\": 4096}\n",
    "    budget = budget_map.get(example[\"complexity\"], 2048)\n",
    "    \n",
    "    print(f\"\\nRecommended reasoning budget: {budget} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b40c32-6f31-4645-9714-d3d2fbcdc97f",
   "metadata": {},
   "source": [
    "## 実用的な移行ワークフロー\n",
    "\n",
    "既存のプロンプトを Claude 3.7 に体系的に移行するには、次の実用的なワークフローに従ってください:\n",
    "\n",
    "### 1. インベントリと優先順位付け\n",
    "- 既存のプロンプトをすべてリストします\n",
    "- 明確な思考の連鎖指示があるプロンプトを特定します\n",
    "- 最もメリットのある複雑な推論タスクを優先します\n",
    "\n",
    "### 2. 現在のプロンプトを分析\n",
    "- 推論指示を特定します\n",
    "- 必要なコンテキストと制約を書き留めます\n",
    "- 出力形式の要件を認識します\n",
    "\n",
    "### 3. 簡素化して移行します\n",
    "- 明示的な推論手順を削除します\n",
    "- 重要なコンテキストと要件を保持します\n",
    "- 移行を支援するために Claude 3.7 自体の使用を検討します\n",
    "\n",
    "### 4. テストと改良\n",
    "- 最小限の推論予算 (1024 トークン) から開始します\n",
    "- タスクの複雑さに基づいて必要に応じて予算を増やします\n",
    "- 結果を比較し、必要に応じて調整します\n",
    "\n",
    "この体系的なアプローチにより、Claude 3.7 の機能を最適化しながら移行を成功させることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc95e92-b2d6-4fc5-b28f-3e1d36fa612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_migration_checklist(prompt):\n",
    "    \"\"\"\n",
    "    Generate a migration checklist for a given prompt\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The original prompt to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Migration recommendations\n",
    "    \"\"\"\n",
    "    analysis_request = f\"\"\"\n",
    "    Analyze this prompt that was designed for Claude 3.5 with chain-of-thought instructions.\n",
    "    \n",
    "    Prompt:\n",
    "    {prompt}\n",
    "    \n",
    "    Please create a migration checklist with the following information in JSON format:\n",
    "    1. Elements to remove (e.g., step-by-step instructions, thinking markers)\n",
    "    2. Elements to preserve (e.g., key context, important constraints)\n",
    "    3. Recommended reasoning budget (1024, 2048, 4096, or 8192 tokens)\n",
    "    4. Complexity assessment (simple, medium, complex, very complex)\n",
    "    \n",
    "    Respond with only the JSON data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get Claude's analysis\n",
    "    response = claude_utils.invoke_claude(\n",
    "        bedrock_runtime,\n",
    "        analysis_request,\n",
    "        CLAUDE_37_SONNET_MODEL_ID,\n",
    "        enable_reasoning=True,\n",
    "        reasoning_budget=2048,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Extract and parse JSON\n",
    "    checklist_text = claude_utils.extract_response_content(response)\n",
    "    \n",
    "    try:\n",
    "        # Try to parse as JSON\n",
    "        import json\n",
    "        checklist = json.loads(checklist_text)\n",
    "        \n",
    "        # Display in a readable format\n",
    "        print(\"Migration Checklist:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"Elements to Remove:\")\n",
    "        for item in checklist.get(\"Elements to remove\", []):\n",
    "            print(f\"- {item}\")\n",
    "            \n",
    "        print(\"\\nElements to Preserve:\")\n",
    "        for item in checklist.get(\"Elements to preserve\", []):\n",
    "            print(f\"- {item}\")\n",
    "            \n",
    "        print(f\"\\nComplexity Assessment: {checklist.get('Complexity assessment', 'Unknown')}\")\n",
    "        print(f\"Recommended Reasoning Budget: {checklist.get('Recommended reasoning budget', 1024)} tokens\")\n",
    "        \n",
    "        return checklist\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing response as JSON. Raw response:\")\n",
    "        print(checklist_text)\n",
    "        return None\n",
    "\n",
    "# Test the migration checklist function\n",
    "complex_prompt = \"\"\"\n",
    "Let's analyze this company's financial performance step by step:\n",
    "\n",
    "1. First, calculate the year-over-year revenue growth rate\n",
    "2. Then, analyze the profit margins (gross, operating, net)\n",
    "3. Next, evaluate the debt-to-equity ratio and liquidity metrics\n",
    "4. Then, compare performance against industry benchmarks\n",
    "5. Finally, identify key strengths and areas for improvement\n",
    "\n",
    "Provide a structured analysis with clear sections for each aspect.\n",
    "\"\"\"\n",
    "\n",
    "migration_checklist = create_migration_checklist(complex_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53de523-e52a-484c-9867-6958393d2cd9",
   "metadata": {},
   "source": [
    "## Handling Complex Migration Scenarios\n",
    "\n",
    "While many prompts can be easily migrated following our patterns, certain scenarios require special consideration:\n",
    "\n",
    "### Multi-Stage Reasoning Workflows\n",
    "\n",
    "For complex workflows that previously relied on a sequence of reasoning steps, the migration strategy needs to:\n",
    "- Preserve critical dependencies between steps\n",
    "- Maintain clarity about the overall goal\n",
    "- Ensure all necessary context is included\n",
    "\n",
    "### Domain-Specific Requirements\n",
    "\n",
    "Some domains (like mathematical proofs, scientific analysis, or code generation) may have specific expectations about:\n",
    "- Notation and formatting\n",
    "- Methodology and approach\n",
    "- Verification and validation\n",
    "\n",
    "Let's examine how to handle these more complex migrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c8527-2967-49d6-9e5a-7937a626303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a multi-stage reasoning workflow\n",
    "multistage_prompt = \"\"\"\n",
    "Let's solve this complex data analysis problem step by step:\n",
    "\n",
    "1. First, analyze the customer segmentation data:\n",
    "   - Identify primary customer segments\n",
    "   - Calculate average revenue per segment\n",
    "   - Determine growth rate for each segment\n",
    "\n",
    "2. Then, evaluate marketing channel effectiveness:\n",
    "   - Compare customer acquisition cost by channel\n",
    "   - Calculate ROI for each marketing channel\n",
    "   - Identify the most and least effective channels\n",
    "\n",
    "3. Next, forecast future performance:\n",
    "   - Project segment growth for next 12 months\n",
    "   - Estimate marketing budget requirements\n",
    "   - Predict overall revenue impact\n",
    "\n",
    "4. Finally, prioritize recommendations:\n",
    "   - Rank segments by potential value\n",
    "   - Suggest budget reallocation between channels\n",
    "   - Propose specific strategies for high-value segments\n",
    "\n",
    "Ensure your analysis follows this structure and provides clear recommendations.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Complex Multi-Stage Workflow Example:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Migrate the prompt\n",
    "_, migrated_multistage = demonstrate_prompt_migration(multistage_prompt, verbose=False)\n",
    "\n",
    "# Show migration results\n",
    "print(\"\\nOriginal Multi-Stage Prompt:\")\n",
    "print(\"-\" * 40)\n",
    "print(multistage_prompt)\n",
    "\n",
    "print(\"\\nMigrated Multi-Stage Prompt:\")\n",
    "print(\"-\" * 40)\n",
    "print(migrated_multistage)\n",
    "\n",
    "# Generate and display migration checklist\n",
    "print(\"\\nMigration Analysis:\")\n",
    "migration_checklist = create_migration_checklist(multistage_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb429c-eb90-4940-b641-e8f9769cd27a",
   "metadata": {},
   "source": [
    "## 移行前と移行後: 全体像\n",
    "\n",
    "移行前と移行後の完全なワークフローを比較して、学んだことをまとめてみましょう。\n",
    "\n",
    "### Claude 3.5 のアプローチ:\n",
    "\n",
    "1. 詳細な思考の連鎖の指示\n",
    "2. 明示的なステップの順序付け\n",
    "3. 構造化された推論ガイダンス\n",
    "4. プロンプトでの思考プロセスの可視化\n",
    "\n",
    "### Claude 3.7 のアプローチ:\n",
    "\n",
    "1. 明確な目標ステートメント\n",
    "2. 関連するコンテキストと制約\n",
    "3. 拡張思考 (内部で処理)\n",
    "4. 適切な推論予算\n",
    "\n",
    "重要な変化は、規範的推論 (Claude に正確にどのように考えるかを伝える) から目標指向推論 (Claude に達成したいことを伝え、その拡張思考でプロセスを処理させる) への変化です。\n",
    "\n",
    "完全なワークフローを並べて比較して、この違いを視覚化してみましょう。\n",
    "![完全なワークフロー](./images/lesson8/compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e3d0f-c647-44af-a50e-e0a8b46862b1",
   "metadata": {},
   "source": [
    "## 移行前と移行後のパフォーマンス ベンチマーク\n",
    "\n",
    "Claude 3.7 の拡張思考への移行のメリットを真に検証するには、パフォーマンスを体系的にベンチマークする必要があります。比較するためのフレームワークを作成しましょう。\n",
    "\n",
    "1. **推論の品質**: 推論はどの程度徹底的かつ正確ですか?\n",
    "\n",
    "2. **応答の効率**: 応答はどの程度効率的に生成されていますか?\n",
    "\n",
    "3. **トークンの使用**: トークンの総消費量を比較するとどうですか?\n",
    "\n",
    "さまざまな種類のプロンプトでこれらのメトリックをベンチマークすることで、データに基づいて移行の決定を下し、移行の実際の影響を理解できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968edd9-d13b-46fc-81b1-60daf44b00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_migration(prompts, reasoning_budgets=None):\n",
    "    \"\"\"\n",
    "    Benchmark performance before and after migration\n",
    "    \n",
    "    Args:\n",
    "        prompts (dict): Dictionary of prompts to benchmark\n",
    "        reasoning_budgets (dict, optional): Dictionary mapping prompt names to reasoning budgets\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Benchmark results\n",
    "    \"\"\"\n",
    "    # Default reasoning budgets if not provided\n",
    "    if reasoning_budgets is None:\n",
    "        reasoning_budgets = {\n",
    "            name: 4096 for name in prompts.keys()\n",
    "        }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, original_prompt in prompts.items():\n",
    "        print(f\"\\nBenchmarking: {name}\")\n",
    "        \n",
    "        # 1. Migrate the prompt\n",
    "        _, migrated_prompt = demonstrate_prompt_migration(original_prompt, verbose=False)\n",
    "        \n",
    "        # 2. Test Claude 3.5 with original prompt\n",
    "        start_time = time.time()\n",
    "        response_35 = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            original_prompt,\n",
    "            CLAUDE_35_SONNET_MODEL_ID,\n",
    "            enable_reasoning=False,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        time_35 = time.time() - start_time\n",
    "        \n",
    "        # 3. Test Claude 3.7 with migrated prompt\n",
    "        start_time = time.time()\n",
    "        response_37 = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            migrated_prompt,\n",
    "            CLAUDE_37_SONNET_MODEL_ID,\n",
    "            enable_reasoning=True,\n",
    "            reasoning_budget=reasoning_budgets.get(name, 4096),\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        time_37 = time.time() - start_time\n",
    "        \n",
    "        # 4. Calculate metrics\n",
    "        tokens_35 = response_35.get('usage', {}).get('totalTokens', 0)\n",
    "        tokens_37 = response_37.get('usage', {}).get('totalTokens', 0)\n",
    "        \n",
    "        # 5. Extract response text to measure length\n",
    "        text_35 = claude_utils.extract_response_content(response_35) or \"\"\n",
    "        text_37 = claude_utils.extract_response_content(response_37) or \"\"\n",
    "        \n",
    "        # 6. Store results\n",
    "        results.append({\n",
    "            'Prompt': name,\n",
    "            'Original Length': len(original_prompt),\n",
    "            'Migrated Length': len(migrated_prompt),\n",
    "            'Prompt Change %': round(((len(migrated_prompt) - len(original_prompt)) / len(original_prompt) * 100), 1),\n",
    "            'Claude 3.5 Tokens': tokens_35,\n",
    "            'Claude 3.7 Tokens': tokens_37,\n",
    "            'Token Change %': round(((tokens_37 - tokens_35) / tokens_35 * 100), 1),\n",
    "            'Claude 3.5 Time (s)': round(time_35, 2),\n",
    "            'Claude 3.7 Time (s)': round(time_37, 2),\n",
    "            'Time Change %': round(((time_37 - time_35) / time_35 * 100), 1),\n",
    "            'Claude 3.5 Output Words': len(text_35.split()),\n",
    "            'Claude 3.7 Output Words': len(text_37.split()),\n",
    "            'Output Change %': round(((len(text_37.split()) - len(text_35.split())) / max(1, len(text_35.split())) * 100), 1),\n",
    "            'Reasoning Budget': reasoning_budgets.get(name, 4096)\n",
    "        })\n",
    "        \n",
    "        print(f\"  Original prompt: {len(original_prompt)} chars\")\n",
    "        print(f\"  Migrated prompt: {len(migrated_prompt)} chars\")\n",
    "        print(f\"  Claude 3.5: {tokens_35} tokens in {time_35:.2f}s\")\n",
    "        print(f\"  Claude 3.7: {tokens_37} tokens in {time_37:.2f}s\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Define prompts for benchmarking\n",
    "benchmark_prompts = {\n",
    "    \"Math Problem\": \"\"\"\n",
    "    Let's solve this probability problem step by step:\n",
    "    1. First, understand what we're looking for\n",
    "    2. Then, identify the probability of each event\n",
    "    3. Next, apply the appropriate probability formula\n",
    "    4. Finally, calculate the answer\n",
    "    \n",
    "    In a standard deck of 52 cards, what is the probability of drawing a face card (J, Q, K) or an ace?\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Business Analysis\": \"\"\"\n",
    "    Let's analyze this business case step by step:\n",
    "    1. First, identify the key issues\n",
    "    2. Then, analyze the market conditions\n",
    "    3. Next, evaluate the financial implications\n",
    "    4. Finally, recommend a course of action\n",
    "    \n",
    "    A retail company is considering expanding to online sales. They have $500K to invest and want to know if they should build their own platform or use an existing marketplace like Amazon.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Code Review\": \"\"\"\n",
    "    Let's review this code step by step:\n",
    "    1. First, understand what the code is trying to do\n",
    "    2. Then, check for logic errors\n",
    "    3. Next, identify performance issues\n",
    "    4. Finally, suggest improvements\n",
    "    \n",
    "    ```python\n",
    "    def find_duplicates(arr):\n",
    "        duplicates = []\n",
    "        for i in range(len(arr)):\n",
    "            for j in range(i+1, len(arr)):\n",
    "                if arr[i] == arr[j] and arr[i] not in duplicates:\n",
    "                    duplicates.append(arr[i])\n",
    "        return duplicates\n",
    "    ```\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Define reasoning budgets for each prompt\n",
    "reasoning_budgets = {\n",
    "    \"Math Problem\": 2048,\n",
    "    \"Business Analysis\": 4096,\n",
    "    \"Code Review\": 4096\n",
    "}\n",
    "\n",
    "# Run the benchmark\n",
    "benchmark_df = benchmark_migration(benchmark_prompts, reasoning_budgets)\n",
    "\n",
    "# Display the results\n",
    "display(HTML(\"<h3>Migration Benchmark Results</h3>\"))\n",
    "display(benchmark_df[['Prompt', 'Prompt Change %', 'Token Change %', 'Time Change %', 'Output Change %', 'Reasoning Budget']])\n",
    "\n",
    "# Create visualizations\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Plot token and time changes\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Token changes\n",
    "    benchmark_df.plot(\n",
    "        x='Prompt', \n",
    "        y=['Claude 3.5 Tokens', 'Claude 3.7 Tokens'], \n",
    "        kind='bar', \n",
    "        ax=ax[0],\n",
    "        color=['skyblue', 'lightgreen']\n",
    "    )\n",
    "    ax[0].set_title('Token Usage Comparison')\n",
    "    ax[0].set_ylabel('Tokens Used')\n",
    "    ax[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Time changes\n",
    "    benchmark_df.plot(\n",
    "        x='Prompt', \n",
    "        y=['Claude 3.5 Time (s)', 'Claude 3.7 Time (s)'], \n",
    "        kind='bar', \n",
    "        ax=ax[1],\n",
    "        color=['skyblue', 'lightgreen']\n",
    "    )\n",
    "    ax[1].set_title('Response Time Comparison')\n",
    "    ax[1].set_ylabel('Time (seconds)')\n",
    "    ax[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Visualization could not be created: {e}\")\n",
    "    print(\"Would display charts comparing token usage and response time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4ee3e-55b7-4e37-8b1d-d300cc5e8e60",
   "metadata": {},
   "source": [
    "## 思考の連鎖要素を保持する場合\n",
    "\n",
    "Claude 3.7 への移行時に思考の連鎖要素を削除することに重点を置いてきましたが、構造化されたプロンプトの特定の側面を保持することが有益な状況がいくつかあります。\n",
    "\n",
    "### 1. 特定の出力形式要件\n",
    "非常に具体的な出力形式が必要な場合は、これを明確に指定すると役立ちます。ただし、*方法* (思考プロセス) ではなく、*内容* (出力形式) に焦点を当ててください。\n",
    "\n",
    "### 2. ドメイン固有の方法論\n",
    "確立された方法論を持つ専門分野 (科学研究、法的分析など) では、必要な方法論を記載すると役立ちます。\n",
    "\n",
    "### 3. 複数の異なるタスク\n",
    "プロンプトに関連のないタスクが複数含まれている場合、これらを個別の項目として構造化すると、応答を整理するのに役立ちます (ただし、推論プロセスは整理できません)。\n",
    "\n",
    "### 4. 非常に小さい推論予算\n",
    "複雑なタスクに最小推論予算 (1024 トークン) を使用している場合は、高レベルの構造を提供すると役立つ場合があります。\n",
    "\n",
    "重要な原則は、Claude が問題をどのように考えるべきかを規定せずに、Claude が達成すべき *内容* をガイドすることです。つまり、推論プロセスは拡張思考に任せます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e38e6-6a0c-4563-b721-bb7bb32d573e",
   "metadata": {},
   "source": [
    "## 結論: 移行戦略チェックリスト\n",
    "\n",
    "Claude 3.5 から Claude 3.7 へのプロンプトの移行プロセスを検討し、拡張された思考機能を活用してパフォーマンスを向上させることに重点を置いています。移行作業のガイドとなるチェックリストを以下に示します。\n",
    "\n",
    "1. **既存のプロンプトを監査する**\n",
    "- 明示的な推論指示のあるプロンプトを特定する\n",
    "- 複雑な推論タスクを優先する\n",
    "- 現在のトークンの使用状況とパフォーマンスを記録する\n",
    "\n",
    "2. **プロンプトを簡素化する**\n",
    "- ステップバイステップの指示を削除する\n",
    "- 明示的な思考マーカーを排除する\n",
    "- 重要なコンテキストと要件を保持する\n",
    "\n",
    "3. **拡張思考を構成する**\n",
    "- 最小の推論予算 (1024 トークン) から開始する\n",
    "- タスクの複雑さに基づいて予算をスケールする\n",
    "- 応答品質を監視し、必要に応じて調整する\n",
    "\n",
    "4. **結果を検証する**\n",
    "- 前後の応答品質を比較する\n",
    "- トークンの使用状況と応答時間を測定\n",
    "- フィードバックに基づいて段階的に改善する\n",
    "\n",
    "### 重要なポイント\n",
    "\n",
    "- 拡張思考により、より自然で柔軟な推論が可能になる\n",
    "- プロンプトがシンプルになると、Claude 3.7 でより良い結果が得られることが多い\n",
    "- タスクの複雑さに基づいて推論予算を選択する\n",
    "- 目的 (目標) ではなく、目的に焦点を当てるそこに到達する方法 (手順)\n",
    "\n",
    "これらのガイドラインに従うことで、既存のワークロードを正常に移行し、Claude 3.7 の高度な機能を最大限に活用できます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
