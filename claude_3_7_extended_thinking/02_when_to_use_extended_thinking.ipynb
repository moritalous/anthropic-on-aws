{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8675320e-4d91-4c30-9a5a-d7ee0be907b8",
   "metadata": {},
   "source": [
    "# 拡張思考をいつ、どのように使用するか\n",
    "\n",
    "このノートブックでは、Claude 3.7 Sonnet の拡張思考機能についてさらに詳しく調べ、次の点について検討します。\n",
    "\n",
    "1. タスクの複雑さの分類フレームワーク\n",
    "2. 拡張思考をいつ使用するかの決定木\n",
    "3. 適切な使用例と不要な使用例の例\n",
    "4. さまざまなタスク タイプでのパフォーマンス ベンチマーク\n",
    "5. コストへの影響と最適化戦略\n",
    "\n",
    "最後には、拡張思考が有益な場合と、特定のアプリケーションで拡張思考の使用を最適化する方法を判断するための体系的なアプローチを習得します。\n",
    "\n",
    "> **注**: このレッスンでは、レッスン 1 で開発したユーティリティ関数を使用します。`claude_utils.py` モジュールには、Bedrock クライアントの作成、拡張思考の有無にかかわらず Claude の呼び出し、応答の表示を行うためのヘルパー関数が含まれています。これにより、定型コードを繰り返すのではなく、拡張思考をいつ、どのように使用するかというコア コンセプトに集中できます。\n",
    ">\n",
    "> レッスン 1 をまだ完了していない場合は、まずレッスン 1 を復習して、これらのユーティリティ関数の動作を理解してください。または、`claude_utils.py` ファイルを直接調べて、実装の詳細を確認することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4faee-702c-4b4f-9e08-377389236f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import claude_utils\n",
    "\n",
    "# Configure plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6548f2-ebb1-424b-b187-bf5a97a63bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Bedrock clients using our utility module\n",
    "REGION = 'us-west-2'  # Change to your preferred region\n",
    "bedrock, bedrock_runtime = claude_utils.create_bedrock_clients(REGION)\n",
    "\n",
    "# Claude 3.7 Sonnet model ID (consistent with Lesson 1)\n",
    "CLAUDE_37_SONNET_MODEL_ID = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "\n",
    "# Verify model availability\n",
    "claude_utils.verify_model_availability(bedrock, CLAUDE_37_SONNET_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1b146-5e1f-4af2-b0bf-ff56978bc158",
   "metadata": {},
   "source": [
    "## 1. タスクの複雑さの分類フレームワーク\n",
    "\n",
    "拡張思考が有益な場合を判断するには、まずタスクの複雑さを分類するフレームワークが必要です。これにより、拡張思考をいつ使用するか、推論にどのくらいの予算を割り当てるかについて体系的な決定を下すことができます。\n",
    "\n",
    "このフレームワークでは、タスクを 4 つのレベルの複雑さに分類します。\n",
    "\n",
    "1. **シンプル**: 単純な事実のクエリ、基本的な情報検索、簡単な計算\n",
    "2. **中程度**: 複数ステップの推論、中程度の数学の問題、基本的な分析タスク\n",
    "3. **複雑**: 詳細な分析、複雑な推論チェーン、制約の問題\n",
    "4. **非常に複雑**: システム設計、高度な数学的証明、多段階の問題解決\n",
    "\n",
    "タスクを複雑さに基づいて自動的に分類できる分類関数を実装しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e3c50-e166-4c9e-b8e3-30a17c21c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_task_complexity(prompt, model_id='us.anthropic.claude-3-5-haiku-20241022-v1:0'):\n",
    "    \"\"\"\n",
    "    Use Claude 3.5 Haiku to quickly classify the complexity of a task\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt to classify\n",
    "        model_id (str): The model ID to use for classification (defaults to Claude 3.5 Haiku for speed/cost)\n",
    "        \n",
    "    Returns:\n",
    "        str: Complexity classification ('simple', 'medium', 'complex', or 'very_complex')\n",
    "    \"\"\"\n",
    "    system_prompt = [\n",
    "        {\n",
    "            \"text\": \"\"\"You are a task complexity classifier. Classify the complexity of the given task into one of these categories: 'simple', 'medium', 'complex', or 'very_complex'. \n",
    "\n",
    "Here are examples of each complexity level:\n",
    "- simple: \"What is the capital of France?\", \"Calculate 25% of 80\", \"Summarize this short paragraph in one sentence\"\n",
    "- medium: \"A man has 53 socks in his drawer: 21 blue, 15 black and 17 red. How many socks must he take out to guarantee a black pair?\", \"Explain the greenhouse effect and its impact on climate\"\n",
    "- complex: \"Design a ride-sharing service that optimizes for driver availability and route efficiency\", \"Analyze the causes and economic impacts of the 2008 financial crisis\"\n",
    "- very_complex: \"Given a graph with n vertices and m edges, design an O(n+m) algorithm to find all bridges\", \"Design a quantum computing algorithm to solve the traveling salesman problem\"\n",
    "\n",
    "Respond with only the category name, nothing else.\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": f\"Classify the complexity of this task: {prompt}\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            system=system_prompt,\n",
    "            inferenceConfig={\n",
    "                \"temperature\": 0,\n",
    "                \"maxTokens\": 10  # We only need a short response\n",
    "            }\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Extract the classification\n",
    "        result = None\n",
    "        if response.get('output', {}).get('message', {}).get('content'):\n",
    "            content_blocks = response['output']['message']['content']\n",
    "            for block in content_blocks:\n",
    "                if 'text' in block:\n",
    "                    result = block['text'].strip().lower()\n",
    "                    break\n",
    "\n",
    "        # Ensure the result is one of our expected categories\n",
    "        valid_categories = ['simple', 'medium', 'complex', 'very_complex']\n",
    "        if result not in valid_categories:\n",
    "            result = 'medium'  # Default to medium if unexpected response\n",
    "\n",
    "        # Calculate approx cost\n",
    "        tokens = response['usage']['totalTokens']\n",
    "        cost = tokens * 0.00000125  # Assuming $0.00125 per 1K tokens for Haiku\n",
    "        \n",
    "        print(f\"Classification: {result} (determined in {elapsed_time:.2f}s, {tokens} tokens, ${cost:.6f})\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying task complexity: {e}\")\n",
    "        return \"medium\"  # Default to medium complexity if there's an error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053aa889-9c84-4bae-b2b9-7d4a5ca7d37a",
   "metadata": {},
   "source": [
    "### タスク複雑度分類子の理解\n",
    "\n",
    "`classify_task_complexity` 関数は、ユーザー プロンプトの複雑度を自動的に分類する効率的な方法です。仕組みは次のとおりです。\n",
    "\n",
    "1. **より小さなモデルを活用**: この分類ステップでは、Claude 3.7 Sonnet ではなく **Claude 3.5 Haiku** を使用します。これは、この単純な決定タスクではより高速でコスト効率が高いためです。\n",
    "\n",
    "2. **分類フレームワーク**: この関数は、4 つの複雑度カテゴリ (シンプル、中程度、複雑、非常に複雑) を定義する明示的な指示と、それぞれの例を添えて、プロンプトを Claude に送信します。\n",
    "\n",
    "3. **効率性に関する考慮事項**: この関数は、次の方法で速度とコストが最適化されています:\n",
    "- より小さなモデルを使用する **(Claude Haiku 3.5)**\n",
    "- 確定的な応答のために温度を 0 に設定する\n",
    "- 出力を 10 トークンに制限する\n",
    "- カテゴリ名のみを要求する\n",
    "\n",
    "4. **実際のアプリケーション**: これをワークフローの「トリアージ」ステップと考えてください。CPU スケジューラがさまざまなタスクに割り当てる処理時間を決定する方法に似ています。この初期評価により、適切な「思考リソース」を手元のタスクに割り当てることができます。\n",
    "\n",
    "このアプローチにより、「思考パイプライン」が作成され、プロセスの各段階に適切なツールを使用して、タスクの要求に基づいて Claude の推論機能を効率的に割り当てることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5c848-46ef-49c4-85d9-12ee00cba970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example tasks of varying complexity\n",
    "example_tasks = {\n",
    "    \"simple_1\": \"What is the capital of France?\",\n",
    "    \"simple_2\": \"What is 15% of 200?\",\n",
    "\n",
    "    \"medium_1\": \"A man has 53 socks in his drawer: 21 identical blue, 15 identical black and 17 identical red. The lights are out, and he is completely in the dark. How many socks must he take out to make 100 percent certain he has at least one pair of black socks?\",\n",
    "    \"medium_2\": \"Compare and contrast reinforcement learning and supervised learning in AI.\",\n",
    "\n",
    "    \"complex_1\": \"Design a system for a ride-sharing service that optimizes for driver availability, passenger wait times, and route efficiency. Include considerations for peak hours, variable pricing, and geographic distribution of drivers.\",\n",
    "    \"complex_2\": \"Analyze the causes and potential solutions to the prisoner's dilemma in game theory, including real-world applications and limitations.\",\n",
    "\n",
    "    \"very_complex_1\": \"Given a graph G with n vertices and m edges, design an algorithm to find all bridges in the graph in O(n+m) time. A bridge is defined as an edge whose removal increases the number of connected components in the graph. Provide pseudocode and explain why your algorithm achieves the desired time complexity.\",\n",
    "    \"very_complex_2\": \"Develop a comprehensive framework for a central bank to implement and manage a central bank digital currency (CBDC), addressing technological architecture, monetary policy implications, privacy concerns, and financial inclusion aspects.\"\n",
    "}\n",
    "\n",
    "# Test the classifier on our examples\n",
    "print(\"Testing Claude Haiku 3.5 task complexity classifier...\\n\")\n",
    "results = {}\n",
    "\n",
    "for label, task in example_tasks.items():\n",
    "    # Show abbreviated prompt if too long\n",
    "    display_prompt = task if len(task) < 100 else task[:97] + \"...\"\n",
    "    print(f\"Task {label}: \\\"{display_prompt}\\\"\")\n",
    "    complexity = classify_task_complexity(task)\n",
    "    results[label] = complexity\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Display summary as a DataFrame\n",
    "#summary_df = pd.DataFrame([(k, v) for k, v in results.items()], \n",
    "#                        columns=['Task', 'Classified Complexity'])\n",
    "#display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd18257-a1d7-4f28-a565-f463d1c0b5d6",
   "metadata": {},
   "source": [
    "## 2. 拡張思考を使用するタイミングの決定ツリー\n",
    "\n",
    "タスクの複雑性フレームワークに基づいて、次の事項を決定するのに役立つ決定ツリーを作成できます。\n",
    "1. 拡張思考を使用するかどうか\n",
    "2. 推論予算をどれだけ割り当てるか\n",
    "\n",
    "決定ツリーでは、次の点を考慮します。\n",
    "- タスクの複雑性\n",
    "- パフォーマンス要件\n",
    "- 時間的制約\n",
    "- コストの考慮事項\n",
    "\n",
    "決定ツリーの視覚化を以下に示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca51b8-cc6c-4685-959c-eb1c87be1346",
   "metadata": {},
   "source": [
    "![Decision Tree](./images/lesson2/complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709763cc-564c-4752-bde0-95df054e96eb",
   "metadata": {},
   "source": [
    "### ここで、拡張思考を使用するかどうか、およびどの予算を割り当てるかを自動的に決定する関数を作成しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca67398-da0c-4061-b616-01b6b39946c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_extended_thinking_strategy(prompt, time_sensitive=False):\n",
    "    \"\"\"\n",
    "    Determine whether to use extended thinking and what budget to allocate\n",
    "    based on task complexity and time sensitivity\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        time_sensitive (bool): Whether the task is time-sensitive\n",
    "        \n",
    "    Returns:\n",
    "        dict: Strategy with 'use_extended_thinking' and 'reasoning_budget' keys\n",
    "    \"\"\"\n",
    "    # First, classify the task complexity\n",
    "    complexity = classify_task_complexity(prompt)\n",
    "    \n",
    "    # Define reasoning budget ranges for each complexity level\n",
    "    budget_ranges = {\n",
    "        'simple': (0, 0),  # No extended thinking for simple tasks\n",
    "        'medium': (1024, 2048),\n",
    "        'complex': (2048, 8192),\n",
    "        'very_complex': (8192, 16384)\n",
    "    }\n",
    "    \n",
    "    # Determine whether to use extended thinking based on complexity and time sensitivity\n",
    "    use_extended_thinking = True\n",
    "    \n",
    "    if complexity == 'simple':\n",
    "        use_extended_thinking = False\n",
    "    elif complexity == 'medium' and time_sensitive:\n",
    "        use_extended_thinking = False\n",
    "    \n",
    "    # Determine reasoning budget (if using extended thinking)\n",
    "    if use_extended_thinking:\n",
    "        min_budget, max_budget = budget_ranges[complexity]\n",
    "        \n",
    "        # Use the lower end of the range if time_sensitive, otherwise use the middle\n",
    "        if time_sensitive:\n",
    "            reasoning_budget = min_budget\n",
    "        else:\n",
    "            reasoning_budget = (min_budget + max_budget) // 2\n",
    "    else:\n",
    "        reasoning_budget = 0\n",
    "    \n",
    "    strategy = {\n",
    "        'complexity': complexity,\n",
    "        'use_extended_thinking': use_extended_thinking,\n",
    "        'reasoning_budget': reasoning_budget,\n",
    "        'time_sensitive': time_sensitive\n",
    "    }\n",
    "    \n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b463c7-2dbd-4844-80f2-0f483e6ddab5",
   "metadata": {},
   "source": [
    "### 拡張思考戦略関数の理解\n",
    "\n",
    "`determine_extended_thinking_strategy` 関数は、意思決定ツリー ロジックを適用する自動意思決定システムとして機能します。まずタスクの複雑さを分類し、次に複雑さと時間的制約の両方に基づいて拡張思考を使用するかどうか、および割り当てる推論予算を決定します。スマート リソース マネージャーのように、タスクの要求に基づいて適切な量の「思考力」を使用して、タスクを適切な処理パイプラインに効率的にルーティングします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a74ea-c51b-4b69-94f2-abed90f771dc",
   "metadata": {},
   "source": [
    "## 3. 適切な使用例と拡張思考が不要な例\n",
    "\n",
    "フレームワークと意思決定ツリーができたので、拡張思考が有益な場合と不要な場合の具体的な例を調べてみましょう。実際のプロンプトを使用して両方のシナリオをテストし、結果を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1376b98-da2c-4970-b672-4825b41d464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_and_without_extended_thinking(prompt, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Test a prompt with and without extended thinking and compare the results\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to test\n",
    "        max_tokens (int): Maximum tokens for the response\n",
    "        \n",
    "    Returns:\n",
    "        dict: Results including both responses and metrics\n",
    "    \"\"\"\n",
    "    print(f\"Testing prompt: {prompt[:100]}...\" if len(prompt) > 100 else f\"Testing prompt: {prompt}\")\n",
    "    \n",
    "    # Determine optimal strategy\n",
    "    strategy = determine_extended_thinking_strategy(prompt)\n",
    "    print(f\"Strategy: Complexity={strategy['complexity']}, Use Extended Thinking={strategy['use_extended_thinking']}, Budget={strategy['reasoning_budget']}\")\n",
    "    \n",
    "    # Test without extended thinking\n",
    "    print(\"\\nTesting WITHOUT extended thinking...\")\n",
    "    standard_response = claude_utils.invoke_claude(\n",
    "        bedrock_runtime,\n",
    "        prompt, \n",
    "        CLAUDE_37_SONNET_MODEL_ID, \n",
    "        enable_reasoning=False,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    # Test with extended thinking (if recommended)\n",
    "    reasoning_response = None\n",
    "    if strategy['use_extended_thinking']:\n",
    "        print(\"\\nTesting WITH extended thinking...\")\n",
    "        reasoning_response = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            prompt, \n",
    "            CLAUDE_37_SONNET_MODEL_ID, \n",
    "            enable_reasoning=True,\n",
    "            reasoning_budget=strategy['reasoning_budget'],\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "    \n",
    "    # Display results\n",
    "    standard_result = claude_utils.extract_response_content(standard_response)\n",
    "    print(\"\\n--- Standard Mode Result ---\")\n",
    "    standard_time = standard_response.get('_elapsed_time', 0)\n",
    "    standard_tokens = standard_response.get('usage', {}).get('totalTokens', 0)\n",
    "    standard_cost = (standard_response.get('usage', {}).get('inputTokens', 0) * 0.000003) + \\\n",
    "                   (standard_response.get('usage', {}).get('outputTokens', 0) * 0.000005)\n",
    "    \n",
    "    print(f\"Time: {standard_time:.2f}s, Tokens: {standard_tokens}, Cost: ${standard_cost:.6f}\")\n",
    "    display(Markdown(f\"**Standard Mode Result:**\\n{standard_result[:500]}...\"))\n",
    "    \n",
    "    # Only show extended thinking results if we used it\n",
    "    reasoning_result = None\n",
    "    if reasoning_response:\n",
    "        reasoning_result = claude_utils.extract_response_content(reasoning_response)\n",
    "        print(\"\\n--- Extended Thinking Mode Result ---\")\n",
    "        reasoning_time = reasoning_response.get('_elapsed_time', 0)\n",
    "        reasoning_tokens = reasoning_response.get('usage', {}).get('totalTokens', 0)\n",
    "        reasoning_cost = (reasoning_response.get('usage', {}).get('inputTokens', 0) * 0.000003) + \\\n",
    "                        (reasoning_response.get('usage', {}).get('outputTokens', 0) * 0.000015)\n",
    "        \n",
    "        print(f\"Time: {reasoning_time:.2f}s, Tokens: {reasoning_tokens}, Cost: ${reasoning_cost:.6f}\")\n",
    "        display(Markdown(f\"**Extended Thinking Mode Result:**\\n{reasoning_result[:500]}...\"))\n",
    "    \n",
    "    return {\n",
    "        'strategy': strategy,\n",
    "        'standard_response': standard_response,\n",
    "        'reasoning_response': reasoning_response,\n",
    "        'standard_result': standard_result,\n",
    "        'reasoning_result': reasoning_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028c0fc-0697-4901-8a15-efd5d547c555",
   "metadata": {},
   "source": [
    "### 次に、拡張思考の適切な使用例と不適切な使用例をいくつかテストしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb17d40-4fd9-4831-94dd-7e09cb3aceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple factual query (should NOT use extended thinking)\n",
    "simple_query = \"What are the three primary colors of light?\"\n",
    "simple_results = test_with_and_without_extended_thinking(simple_query)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Example 2: Complex reasoning task (SHOULD use extended thinking)\n",
    "complex_query = \"\"\"\n",
    "Analyze the knapsack problem in computer science. Explain the dynamic programming approach \n",
    "to solve it, provide pseudocode, and analyze the time and space complexity. \n",
    "Also explain when a greedy approach might work and when it would fail.\n",
    "\"\"\"\n",
    "complex_results = test_with_and_without_extended_thinking(complex_query, max_tokens=800)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Example 3: Medium complexity task (may use extended thinking if not time-sensitive)\n",
    "medium_query = \"\"\"\n",
    "Compare and contrast supervised learning and unsupervised learning in machine learning. \n",
    "Give examples of algorithms in each category and scenarios where one would be preferred over the other.\n",
    "\"\"\"\n",
    "medium_results = test_with_and_without_extended_thinking(medium_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4092385-54ff-41e2-8507-4e2114f7f635",
   "metadata": {},
   "source": [
    "## 4. さまざまなタスク タイプでのパフォーマンス ベンチマーク\n",
    "\n",
    "個々の例を確認したので、拡張思考の有無にかかわらず、さまざまなタスク タイプで Claude のパフォーマンスを体系的にベンチマークしてみましょう。いくつかの主要な指標を測定します:\n",
    "\n",
    "1. **応答品質** (定性評価)\n",
    "2. **応答生成時間** (レイテンシ)\n",
    "3. **トークン使用量** (および関連コスト)\n",
    "4. **効率** (1 秒あたりのトークン数)\n",
    "\n",
    "このベンチマークにより、さまざまなタスク タイプで拡張思考と標準モードを使用することのトレードオフを定量化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc366c-4fcc-4efc-aa28-efac1a1dd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmarking_comparison(tasks, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Run a systematic benchmarking comparison across different task types\n",
    "    \n",
    "    Args:\n",
    "        tasks (dict): Dictionary of task labels to prompts\n",
    "        max_tokens (int): Maximum tokens for responses\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Benchmarking results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for label, prompt in tasks.items():\n",
    "        print(f\"\\nBenchmarking task: {label}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 1. Test without extended thinking\n",
    "        print(f\"Testing standard mode...\")\n",
    "        standard_start = time.time()\n",
    "        standard_response = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            prompt, \n",
    "            CLAUDE_37_SONNET_MODEL_ID, \n",
    "            enable_reasoning=False,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        standard_time = time.time() - standard_start\n",
    "        \n",
    "        standard_input_tokens = standard_response.get('usage', {}).get('inputTokens', 0)\n",
    "        standard_output_tokens = standard_response.get('usage', {}).get('outputTokens', 0)\n",
    "        standard_total_tokens = standard_response.get('usage', {}).get('totalTokens', 0)\n",
    "        standard_cost = (standard_input_tokens * 0.000003) + (standard_output_tokens * 0.000015)\n",
    "        \n",
    "        # 2. Test with extended thinking\n",
    "        print(f\"Testing extended thinking mode...\")\n",
    "        # Determine appropriate budget based on complexity\n",
    "        complexity = classify_task_complexity(prompt)\n",
    "        budget_map = {\n",
    "            'simple': 1024,\n",
    "            'medium': 2048,\n",
    "            'complex': 4096,\n",
    "            'very_complex': 8192\n",
    "        }\n",
    "        budget = budget_map.get(complexity, 2048)\n",
    "        \n",
    "        reasoning_start = time.time()\n",
    "        reasoning_response = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            prompt, \n",
    "            CLAUDE_37_SONNET_MODEL_ID, \n",
    "            enable_reasoning=True,\n",
    "            reasoning_budget=budget,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        reasoning_time = time.time() - reasoning_start\n",
    "        \n",
    "        reasoning_input_tokens = reasoning_response.get('usage', {}).get('inputTokens', 0)\n",
    "        reasoning_output_tokens = reasoning_response.get('usage', {}).get('outputTokens', 0)\n",
    "        reasoning_total_tokens = reasoning_response.get('usage', {}).get('totalTokens', 0)\n",
    "        reasoning_cost = (reasoning_input_tokens * 0.000003) + (reasoning_output_tokens * 0.000015)\n",
    "        \n",
    "        # Calculate efficiency metrics\n",
    "        standard_efficiency = standard_total_tokens / standard_time if standard_time > 0 else 0\n",
    "        reasoning_efficiency = reasoning_total_tokens / reasoning_time if reasoning_time > 0 else 0\n",
    "        \n",
    "        # Collect results\n",
    "        result = {\n",
    "            'Task': label,\n",
    "            'Complexity': complexity,\n",
    "            'Standard_Time': standard_time,\n",
    "            'Standard_Tokens': standard_total_tokens,\n",
    "            'Standard_Cost': standard_cost,\n",
    "            'Standard_Efficiency': standard_efficiency,\n",
    "            'Reasoning_Time': reasoning_time,\n",
    "            'Reasoning_Tokens': reasoning_total_tokens,\n",
    "            'Reasoning_Cost': reasoning_cost,\n",
    "            'Reasoning_Efficiency': reasoning_efficiency,\n",
    "            'Time_Ratio': reasoning_time / standard_time if standard_time > 0 else 0,\n",
    "            'Cost_Ratio': reasoning_cost / standard_cost if standard_cost > 0 else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"Results: {complexity} task\")\n",
    "        print(f\"Standard: {standard_time:.2f}s, {standard_total_tokens} tokens, ${standard_cost:.6f}\")\n",
    "        print(f\"Reasoning: {reasoning_time:.2f}s, {reasoning_total_tokens} tokens, ${reasoning_cost:.6f}\")\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Define benchmark tasks\n",
    "benchmark_tasks = {\n",
    "    \"FactualQuery\": \"What are the major planets in our solar system?\",\n",
    "    \"SimpleCalc\": \"If I have 5 apples and give away 2, then buy 3 more, how many do I have?\",\n",
    "    \"MediumAnalysis\": \"Compare the advantages and disadvantages of renewable energy vs. fossil fuels.\",\n",
    "    \"SockDrawer\": \"A man has 53 socks in his drawer: 21 identical blue, 15 identical black and 17 identical red. The lights are out, and he is completely in the dark. How many socks must he take out to make 100 percent certain he has at least one pair of black socks?\",\n",
    "    \"ComplexDesign\": \"Design a system for coordinating autonomous delivery drones in an urban environment, considering obstacles, weather, traffic patterns, and regulatory compliance.\",\n",
    "    \"AdvancedCoding\": \"Explain how you would implement a distributed system for real-time processing of financial transactions that ensures ACID properties while maintaining high throughput.\"\n",
    "}\n",
    "\n",
    "# Run the benchmarking comparison\n",
    "benchmark_results = run_benchmarking_comparison(benchmark_tasks)\n",
    "\n",
    "# Display results\n",
    "display(benchmark_results)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Time comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "benchmark_results.plot(kind='bar', x='Task', y=['Standard_Time', 'Reasoning_Time'], ax=plt.gca())\n",
    "plt.title('Response Time Comparison')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. Cost comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "benchmark_results.plot(kind='bar', x='Task', y=['Standard_Cost', 'Reasoning_Cost'], ax=plt.gca())\n",
    "plt.title('Cost Comparison')\n",
    "plt.ylabel('Cost ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 3. Efficiency comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "benchmark_results.plot(kind='bar', x='Task', y=['Standard_Efficiency', 'Reasoning_Efficiency'], ax=plt.gca())\n",
    "plt.title('Efficiency Comparison (Tokens/Second)')\n",
    "plt.ylabel('Tokens per Second')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 4. Ratio analysis by complexity\n",
    "plt.subplot(2, 2, 4)\n",
    "complexity_order = ['simple', 'medium', 'complex', 'very_complex']\n",
    "benchmark_results['Complexity'] = pd.Categorical(benchmark_results['Complexity'], categories=complexity_order, ordered=True)\n",
    "benchmark_results.sort_values('Complexity', inplace=True)\n",
    "\n",
    "# Create separate scatter plots for each ratio instead of trying to plot both at once\n",
    "benchmark_results.plot(kind='scatter', x='Complexity', y='Time_Ratio', color='blue', label='Time Ratio', ax=plt.gca())\n",
    "benchmark_results.plot(kind='scatter', x='Complexity', y='Cost_Ratio', color='red', label='Cost Ratio', ax=plt.gca())\n",
    "\n",
    "plt.title('Extended Thinking/Standard Ratios by Complexity')\n",
    "plt.ylabel('Ratio (Extended/Standard)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4163f2-a301-44ae-b0a0-1eebb21f29a3",
   "metadata": {},
   "source": [
    "### ベンチマーク機能の理解\n",
    "\n",
    "`run_benchmarking_comparison` 関数は、実験室として機能し、拡張思考の有無にかかわらず、さまざまなタスク タイプで Claude のパフォーマンスを体系的にテストします。タスクごとに、応答時間、トークンの使用、コスト、効率の指標を測定し、パフォーマンスのトレードオフを正確に定量化し、拡張思考が最も価値を発揮する場所を判断できます。これは、事例証拠を超えて、拡張思考をいつ使用するかについてのデータに基づくガイドラインを作成するのに役立つ、制御された実験と考えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ef21c-bcb7-4205-bbd2-1a880762b2c1",
   "metadata": {},
   "source": [
    "## 5. コストへの影響と最適化戦略\n",
    "\n",
    "ベンチマーク結果に基づいて、Claude の拡張思考機能を使用する際のコストとパフォーマンスのトレードオフを最適化するための戦略をいくつか開発できます。\n",
    "\n",
    "### コスト構造\n",
    "\n",
    "Claude 3.7 Sonnet の価格は、標準思考モードと拡張思考モードの両方で一貫しています。\n",
    "- **入力トークン**: 100 万トークンあたり 3 ドル\n",
    "- **出力トークン**: 100 万トークンあたり 15 ドル (思考トークンを含む)\n",
    "\n",
    "つまり、拡張思考は主に推論に使用される追加の出力トークンを通じてコストを増加させます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de32a0-940c-42c0-9be3-0b5dd23c899c",
   "metadata": {},
   "source": [
    "### 最適化戦略\n",
    "\n",
    "コストと利益のトレードオフを最適化するためのいくつかの戦略を検討してみましょう:\n",
    "\n",
    "| 戦略 | 説明 | 使用する場合 |\n",
    "|---------|-------------|--------------|\n",
    "| タスクの複雑さのフィルタリング | 複雑なタスクと非常に複雑なタスクにのみ拡張思考を使用します | 分類子を適用して、単純なタスクを標準モードにルーティングします |\n",
    "| 動的な予算割り当て | タスクの複雑さに基づいて推論予算を割り当てます | 複雑さに基づいて、予算を 1024 トークン (最小) から 16384 トークン以上にスケーリングします |\n",
    "| 2 段階アプローチ | 最初に標準モードを使用し、必要な場合にのみ拡張思考を呼び出します | 不確実なケースまたは標準モードの信頼性が低い場合 |\n",
    "| 類似タスクのバッチ処理 | 分類コストを償却するために類似タスクをグループ化します | 多数の類似リクエストを処理するアプリケーション (例: カスタマー サービス) の場合 |\n",
    "| 推論予算の上限 | ROI 分析に基づいて推論予算の上限を設定する | 予算が高額になると収益が減少することが観察される場合 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84583941-4c77-4397-af4c-85e1facfc175",
   "metadata": {},
   "source": [
    "### 実装例: コスト最適化された拡張思考\n",
    "\n",
    "以下は、コストとパフォーマンスのバランスをとる最適化されたアプローチの実装です。この機能は次のようになります:\n",
    "\n",
    "1. 複雑性分類器を使用して、拡張思考が必要かどうかを判断します\n",
    "2. 複雑性に基づいて適切な推論予算を割り当てます\n",
    "3. 予算上限を適用して、トークンの過剰使用を防止します\n",
    "4. 詳細な監視メトリックを通じて透明性を提供します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a95cc4-9cf5-4e59-ab7b-7f5ea51d7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_optimized_invoke(prompt, time_sensitive=False, max_tokens=1000):\n",
    "    \"\"\"\n",
    "    Invoke Claude with cost-optimized extended thinking\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        time_sensitive (bool): Whether the task is time-sensitive\n",
    "        max_tokens (int): Maximum tokens for the final response\n",
    "        \n",
    "    Returns:\n",
    "        dict: Response and performance metrics\n",
    "    \"\"\"\n",
    "    # Step 1: Determine strategy\n",
    "    strategy = determine_extended_thinking_strategy(prompt, time_sensitive=time_sensitive)\n",
    "    \n",
    "    # Step 2: Apply budget caps based on ROI analysis\n",
    "    # (These caps would ideally be determined through extensive benchmarking)\n",
    "    budget_caps = {\n",
    "        'simple': 0,\n",
    "        'medium': 2048,\n",
    "        'complex': 4096,\n",
    "        'very_complex': 8192\n",
    "    }\n",
    "    \n",
    "    if strategy['use_extended_thinking']:\n",
    "        strategy['reasoning_budget'] = min(strategy['reasoning_budget'], budget_caps[strategy['complexity']])\n",
    "    \n",
    "    # Step 3: Invoke Claude with the optimized settings\n",
    "    response = claude_utils.invoke_claude(\n",
    "        bedrock_runtime,\n",
    "        prompt,\n",
    "        CLAUDE_37_SONNET_MODEL_ID,\n",
    "        enable_reasoning=strategy['use_extended_thinking'],\n",
    "        reasoning_budget=strategy['reasoning_budget'],\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    # Step 4: Calculate performance metrics\n",
    "    elapsed_time = response.get('_elapsed_time', 0)\n",
    "    input_tokens = response.get('usage', {}).get('inputTokens', 0)\n",
    "    output_tokens = response.get('usage', {}).get('outputTokens', 0)\n",
    "    total_tokens = response.get('usage', {}).get('totalTokens', 0)\n",
    "    \n",
    "    input_cost = input_tokens * 0.000003\n",
    "    output_cost = output_tokens * 0.000005\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    metrics = {\n",
    "        'strategy': strategy,\n",
    "        'elapsed_time': elapsed_time,\n",
    "        'input_tokens': input_tokens,\n",
    "        'output_tokens': output_tokens,\n",
    "        'total_tokens': total_tokens,\n",
    "        'input_cost': input_cost,\n",
    "        'output_cost': output_cost,\n",
    "        'total_cost': total_cost\n",
    "    }\n",
    "    \n",
    "    # Add the metrics to the response for transparency\n",
    "    response['_metrics'] = metrics\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Demonstrate the cost-optimized approach\n",
    "print(\"Testing cost-optimized approach...\")\n",
    "test_prompt = \"\"\"\n",
    "A spaceship needs to visit 5 planets (A, B, C, D, and E) starting from Earth and then returning to Earth. \n",
    "The distances between each pair of locations are as follows (in light-years):\n",
    "Earth-A: 5, Earth-B: 7, Earth-C: 8, Earth-D: 10, Earth-E: 12\n",
    "A-B: 4, A-C: 6, A-D: 9, A-E: 11\n",
    "B-C: 5, B-D: 8, B-E: 10\n",
    "C-D: 6, C-E: 9\n",
    "D-E: 7\n",
    "\n",
    "What's the shortest possible route that visits each planet exactly once before returning to Earth?\n",
    "\"\"\"\n",
    "\n",
    "cost_optimized_response = cost_optimized_invoke(test_prompt)\n",
    "claude_utils.display_claude_response(cost_optimized_response)\n",
    "\n",
    "# Display the optimization metrics\n",
    "metrics = cost_optimized_response.get('_metrics', {})\n",
    "print(\"\\nOptimization Metrics:\")\n",
    "print(f\"Task Complexity: {metrics.get('strategy', {}).get('complexity', 'unknown')}\")\n",
    "print(f\"Extended Thinking Used: {metrics.get('strategy', {}).get('use_extended_thinking', False)}\")\n",
    "print(f\"Reasoning Budget: {metrics.get('strategy', {}).get('reasoning_budget', 0)} tokens\")\n",
    "print(f\"Time: {metrics.get('elapsed_time', 0):.2f} seconds\")\n",
    "print(f\"Cost: ${metrics.get('total_cost', 0):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3288d0-95ab-4782-ab7c-c21aaba025f5",
   "metadata": {},
   "source": [
    "## 結論: 拡張思考を効果的に使用するためのフレームワーク\n",
    "\n",
    "Claude の拡張思考機能をいつ使用するか、またその使用を最適化する方法を決定するための体系的なフレームワークを開発しました:\n",
    "\n",
    "1. 自動化された分類器を使用して **タスクの複雑さを分類**\n",
    "2. **決定木を適用**して、拡張思考が必要かどうかを判断\n",
    "3. 複雑さに基づいて **適切な推論予算を割り当てる**\n",
    "4. **パフォーマンス メトリックを監視し**、アプローチを継続的に改善\n",
    "\n",
    "このフレームワークに従うことで、次のことが可能になります:\n",
    "- 複雑なタスクの応答品質を向上させる\n",
    "- 単純なタスクの不要なコストを回避する\n",
    "- パフォーマンスとコストの考慮事項のバランスをとる\n",
    "- 特定の要件に基づいてアプローチを調整する\n",
    "\n",
    "次のノートブックでは、ここで確立した基盤に基づいて、推論予算の割り当てを最適化する方法をさらに詳しく検討します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
