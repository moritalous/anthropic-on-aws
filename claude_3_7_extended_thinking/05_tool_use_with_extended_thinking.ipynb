{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4556408-dc62-4a39-ab21-b01f834eac30",
   "metadata": {},
   "source": [
    "# ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã¨æ‹¡å¼µæ€è€ƒã®çµ±åˆ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Claude 3.7 Sonnet ã®æ‹¡å¼µæ€è€ƒæ©Ÿèƒ½ã¨ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ©Ÿèƒ½ã‚’åŠ¹æœçš„ã«çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ã“ã®ãƒ¬ãƒƒã‚¹ãƒ³ã®çµ‚ã‚ã‚Šã¾ã§ã«ã€æ¬¡ã®ã“ã¨ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "1. æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’é€£æºã•ã›ã‚‹æ–¹æ³•\n",
    "2. ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãªæ¨è«–ã‹ã‚‰ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã™ã‚‹æ–¹æ³•\n",
    "3. æ¨è«–ã¨ãƒ„ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•\n",
    "4. ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã€å•é¡Œã‹ã‚‰å›å¾©ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥\n",
    "\n",
    "ã“ã‚Œã‚‰ã®æ¦‚å¿µã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ã€è¨ˆç®—æ©Ÿã€å¤©æ°— APIã€Wikipedia æ¤œç´¢ãªã©ã®åŸºæœ¬çš„ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸã‚·ãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨çš„ãªä¾‹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "\n",
    "- Claude 3.7 ã®æ‹¡å¼µæ€è€ƒæ©Ÿèƒ½ã«é–¢ã™ã‚‹åŸºæœ¬çš„ãªç†è§£ (ä»¥å‰ã®ãƒ¬ãƒƒã‚¹ãƒ³ã§èª¬æ˜)\n",
    "- Bedrock API ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã«é–¢ã™ã‚‹çŸ¥è­˜\n",
    "- Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®çµŒé¨“\n",
    "\n",
    "ã¾ãšã€ç’°å¢ƒã®è¨­å®šã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8905a8-0c99-4017-9851-d625efb2f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import requests\n",
    "import math\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our utility functions from previous lessons\n",
    "import claude_utils\n",
    "\n",
    "# Set up the Bedrock clients using our utility module\n",
    "REGION = 'us-west-2'  # Change to your preferred region\n",
    "bedrock, bedrock_runtime = claude_utils.create_bedrock_clients(REGION)\n",
    "\n",
    "# Claude 3.7 Sonnet model ID\n",
    "CLAUDE_37_SONNET_MODEL_ID = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "\n",
    "# Verify model availability\n",
    "claude_utils.verify_model_availability(bedrock, CLAUDE_37_SONNET_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e059e2-629d-465d-9062-67b0b9a16b0f",
   "metadata": {},
   "source": [
    "## æ‹¡å¼µæ€è€ƒã«ã‚ˆã‚‹ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã®ç†è§£\n",
    "\n",
    "Claude 3.7 Sonnet ã¯ã€æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã¨ã„ã† 2 ã¤ã®å¼·åŠ›ãªæ©Ÿèƒ½ã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã‚’åŠ¹æœçš„ã«çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€äººé–“ãŒè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å–ã‚Šçµ„ã‚€æ–¹æ³•ã‚’æ¨¡å€£ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒä½œæˆã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "1. **æ‹¡å¼µæ€è€ƒ**: ã‚¯ãƒ­ãƒ¼ãƒ‰ã¯å°‚ç”¨ã®ã€Œã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰ã€ã‚¹ãƒšãƒ¼ã‚¹ã§å•é¡Œã‚’æ®µéšçš„ã«è€ƒãˆã¾ã™\n",
    "\n",
    "2. **ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨**: ã‚¯ãƒ­ãƒ¼ãƒ‰ã¯å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’è¦æ±‚ã—ã¦ä½¿ç”¨ã—ã€æƒ…å ±ã‚’åé›†ã—ãŸã‚Šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ãŸã‚Šã—ã¾ã™\n",
    "\n",
    "### ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ« ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "\n",
    "æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€ã‚¯ãƒ­ãƒ¼ãƒ‰ã¯ç‰¹å®šã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¾“ã„ã¾ã™ã€‚\n",
    "\n",
    "1. ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ ã‚¿ãƒ¼ãƒ³ã”ã¨ã« 1 ã¤ã®æ‹¡å¼µæ€è€ƒãƒ–ãƒ­ãƒƒã‚¯ (ã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰)\n",
    "\n",
    "2. ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã® 1 ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”\n",
    "\n",
    "3. å¯èƒ½ãªãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒç¶šãã¾ã™\n",
    "\n",
    "ã¤ã¾ã‚Šã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n",
    "- æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒäº¤äº’ã«è¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“\n",
    "- æ‹¡å¼µæ€è€ƒãŒæœ€åˆã«ç™ºç”Ÿã—ã€ãã®å¾Œã«ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒç¶šãã¾ã™\n",
    "- æ‹¡å¼µæ€è€ƒè‡ªä½“å†…ã§ã®ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“\n",
    "\n",
    "ãƒ—ãƒ­ã‚»ã‚¹ã®è¦–è¦šåŒ–ã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ã€‚\n",
    "\n",
    "[ãƒ¦ãƒ¼ã‚¶ãƒ¼ ã‚¯ã‚¨ãƒª] â†’ [æ‹¡å¼µæ€è€ƒ] â†’ [ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”] â†’ [ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—] â†’ [ãƒ„ãƒ¼ãƒ«çµæœ] â†’ [æ¬¡ã®ã‚¿ãƒ¼ãƒ³]\n",
    "\n",
    "ã“ã‚Œã‚’äººé–“ã®ã‚ˆã†ã«è€ƒãˆã¾ã™1. ã¾ãšå•é¡Œã‚’æ…é‡ã«è€ƒãˆã‚‹\n",
    "2. æ¬¡ã«ç†ç”±ã‚’èª¬æ˜ã™ã‚‹\n",
    "3. æœ€å¾Œã«ãã®ç†ç”±ã«åŸºã¥ã„ã¦è¡Œå‹•ã™ã‚‹\n",
    "\n",
    "ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€æ…é‡ãªæ¨è«–ã¨å¤–éƒ¨ã®æƒ…å ±ã‚„æ©Ÿèƒ½ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã®ä¸¡æ–¹ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«ç‰¹ã«åŠ¹æœçš„ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11e0ec-5c6e-4b3c-b18a-72f3c94cfd40",
   "metadata": {},
   "source": [
    "## ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€`claude_utils.py` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã„ãã¤ã‹ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€Claude ã®ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ©Ÿèƒ½ã®æ“ä½œã‚’åŠ¹ç‡åŒ–ã—ã¾ã™ã€‚\n",
    "\n",
    "- `define_tool`: åå‰ã€èª¬æ˜ã€ãŠã‚ˆã³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ã‚¹ã‚­ãƒ¼ãƒã‚’å«ã‚€ãƒ„ãƒ¼ãƒ«ä»•æ§˜ã‚’ä½œæˆã—ã¾ã™\n",
    "- `handle_tool_call`: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å‡¦ç†ã—ã€é©åˆ‡ãªãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–¢æ•°ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã—ã¾ã™\n",
    "- `calculate`ã€`get_weather`ã€`search_wikipedia`: å€‹ã€…ã®ãƒ„ãƒ¼ãƒ«å®Ÿè£…\n",
    "- `get_common_tools`: äº‹å‰æ§‹æˆã•ã‚ŒãŸä¸€èˆ¬çš„ãªãƒ„ãƒ¼ãƒ«ã®è¾æ›¸ã‚’è¿”ã—ã¾ã™\n",
    "\n",
    "ã“ã‚Œã‚‰ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å®Ÿè£…ã®è©³ç´°ã«è¿·ã†ã“ã¨ãªãã€æ‹¡å¼µã•ã‚ŒãŸæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã„ã†ã‚³ã‚¢ ã‚³ãƒ³ã‚»ãƒ—ãƒˆã«é›†ä¸­ã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¹ ã‚±ãƒ¼ã‚¹ã«å›ºæœ‰ã®æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã“ã‚Œã‚‰ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’ç‹¬è‡ªã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«é©å¿œã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "ç°¡å˜ã«ã™ã‚‹ãŸã‚ã«ã€ã‚µãƒ³ãƒ—ãƒ« ãƒ„ãƒ¼ãƒ«ã§ã¯å¤–éƒ¨ API ã‚’å‘¼ã³å‡ºã™ã®ã§ã¯ãªãã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ ã‚½ãƒ¼ã‚¹ã«æ¥ç¶šã™ã‚‹å ´åˆã‚‚ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯åŒã˜ã§ã™ã€‚\n",
    "\n",
    "ãã‚Œã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¯ãƒ­ãƒ¼ãƒ‰æ°ã®æ‹¡å¼µæ€è€ƒèƒ½åŠ›ãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb193c76-5a84-4ba0-9354-bc4c3f22a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our utility functions\n",
    "from claude_utils import define_tool, handle_tool_call, get_common_tools\n",
    "\n",
    "# Get the common tools\n",
    "tools = get_common_tools()\n",
    "calculator_tool = tools[\"calculator\"]\n",
    "weather_tool = tools[\"weather\"]\n",
    "wikipedia_tool = tools[\"wikipedia\"]\n",
    "\n",
    "# Display the tools\n",
    "print(f\"Loaded {len(tools)} tools:\")\n",
    "for name, tool in tools.items():\n",
    "    print(f\"- {tool['toolSpec']['name']}: {tool['toolSpec']['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e140dc-b72f-487a-b9a2-a14f42f4fc57",
   "metadata": {},
   "source": [
    "#### ãƒ„ãƒ¼ãƒ« ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å®Ÿè£…ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecd4d3-49aa-4598-ab26-409f58331485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(tool_name, tool_input):\n",
    "    \"\"\"\n",
    "    Handle tool calls by executing the appropriate function\n",
    "    \n",
    "    Args:\n",
    "        tool_name (str): Name of the tool to call\n",
    "        tool_input (dict): Parameters for the tool\n",
    "        \n",
    "    Returns:\n",
    "        str or dict: Result of the tool execution\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if tool_name == \"calculator\":\n",
    "            return calculate(tool_input[\"expression\"])\n",
    "        elif tool_name == \"get_weather\":\n",
    "            return get_weather(tool_input[\"location\"], tool_input.get(\"unit\", \"celsius\"))\n",
    "        elif tool_name == \"search_wikipedia\":\n",
    "            return search_wikipedia(tool_input[\"query\"], tool_input.get(\"max_results\", 3))\n",
    "        else:\n",
    "            return {\"error\": f\"Unknown tool: {tool_name}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error executing {tool_name}: {str(e)}\"}\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Simple calculator function\"\"\"\n",
    "    # Remove any potentially unsafe operations\n",
    "    if any(unsafe in expression for unsafe in [\"import\", \"exec\", \"eval\", \"compile\", \"open\", \"__\"]):\n",
    "        return {\"error\": \"Unsafe expression\"}\n",
    "    \n",
    "    try:\n",
    "        # Use a safer approach to evaluate mathematical expressions\n",
    "        # This is a simplified version - in production you'd want more safeguards\n",
    "        allowed_symbols = {\n",
    "            'sqrt': math.sqrt, 'pi': math.pi, 'e': math.e,\n",
    "            'sin': math.sin, 'cos': math.cos, 'tan': math.tan,\n",
    "            'log': math.log, 'log10': math.log10, 'exp': math.exp,\n",
    "            'floor': math.floor, 'ceil': math.ceil, 'abs': abs\n",
    "        }\n",
    "        \n",
    "        # Replace common math operations with Python syntax\n",
    "        expression = expression.replace('^', '**')\n",
    "        result = eval(expression, {\"__builtins__\": {}}, allowed_symbols)\n",
    "        return {\"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to calculate: {str(e)}\"}\n",
    "\n",
    "def get_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"Simulate getting weather data for a location\"\"\"\n",
    "    # In a real application, you would call a weather API\n",
    "    # For this example, we'll just return simulated data\n",
    "    \n",
    "    weather_data = {\n",
    "        \"New York, USA\": {\"temp\": 22, \"conditions\": \"Partly Cloudy\", \"humidity\": 65},\n",
    "        \"London, UK\": {\"temp\": 18, \"conditions\": \"Rainy\", \"humidity\": 78},\n",
    "        \"Tokyo, Japan\": {\"temp\": 26, \"conditions\": \"Sunny\", \"humidity\": 60},\n",
    "        \"Sydney, Australia\": {\"temp\": 24, \"conditions\": \"Clear\", \"humidity\": 55},\n",
    "        \"Paris, France\": {\"temp\": 20, \"conditions\": \"Cloudy\", \"humidity\": 70}\n",
    "    }\n",
    "    \n",
    "    # Default to a generic response if location not found\n",
    "    data = weather_data.get(location, {\"temp\": 21, \"conditions\": \"Unknown\", \"humidity\": 65})\n",
    "    \n",
    "    # Convert temperature if needed\n",
    "    if unit.lower() == \"fahrenheit\":\n",
    "        data[\"temp\"] = (data[\"temp\"] * 9/5) + 32\n",
    "    \n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": data[\"temp\"],\n",
    "        \"unit\": unit,\n",
    "        \"conditions\": data[\"conditions\"],\n",
    "        \"humidity\": data[\"humidity\"],\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "def search_wikipedia(query, max_results=3):\n",
    "    \"\"\"Simulate searching Wikipedia\"\"\"\n",
    "    # In a real application, you would use the Wikipedia API\n",
    "    # For this example, we'll just return simulated data\n",
    "    \n",
    "    wiki_results = {\n",
    "        \"python\": [\n",
    "            {\"title\": \"Python (programming language)\", \"snippet\": \"Python is a high-level, interpreted programming language known for its readability and versatility...\"},\n",
    "            {\"title\": \"Python (genus)\", \"snippet\": \"Python is a genus of constricting snakes in the Pythonidae family native to the tropics and subtropics...\"},\n",
    "            {\"title\": \"Monty Python\", \"snippet\": \"Monty Python was a British surreal comedy troupe formed in 1969...\"}\n",
    "        ],\n",
    "        \"climate change\": [\n",
    "            {\"title\": \"Climate change\", \"snippet\": \"Climate change refers to long-term shifts in temperatures and weather patterns...\"},\n",
    "            {\"title\": \"Global warming\", \"snippet\": \"Global warming is the long-term heating of Earth's climate system observed since the pre-industrial period...\"},\n",
    "            {\"title\": \"Climate change mitigation\", \"snippet\": \"Climate change mitigation consists of actions to limit global warming...\"}\n",
    "        ],\n",
    "        \"artificial intelligence\": [\n",
    "            {\"title\": \"Artificial intelligence\", \"snippet\": \"Artificial intelligence (AI) is intelligence demonstrated by machines...\"},\n",
    "            {\"title\": \"Machine learning\", \"snippet\": \"Machine learning is a field of inquiry devoted to understanding and building methods that 'learn'...\"},\n",
    "            {\"title\": \"History of artificial intelligence\", \"snippet\": \"The history of artificial intelligence began in antiquity, with myths, stories and rumors...\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Handle case-insensitivity with fallbacks\n",
    "    query_lower = query.lower()\n",
    "    for key in wiki_results.keys():\n",
    "        if query_lower in key or key in query_lower:\n",
    "            query_lower = key\n",
    "            break\n",
    "    \n",
    "    results = wiki_results.get(query_lower, [\n",
    "        {\"title\": f\"No exact match for '{query}'\", \"snippet\": \"Try another search term...\"}\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"results\": results[:max_results],\n",
    "        \"total_results\": len(results),\n",
    "        \"search_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9fb9a-3e5e-4d9e-8d0f-7f2777b41631",
   "metadata": {},
   "source": [
    "#### ã“ã“ã§ã€æ‹¡å¼µã•ã‚ŒãŸæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã§ Claude ã‚’å‘¼ã³å‡ºã™é–¢æ•°ã‚’å®Ÿè£…ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a632476-f599-42e6-a0d5-84a0a628f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_claude_with_tools(prompt, tools, reasoning_budget=4096, max_tokens=1000):\n",
    "    \"\"\"\n",
    "    Invoke Claude with both extended thinking and tool use capabilities\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        tools (list): List of tools to make available\n",
    "        reasoning_budget (int): Token budget for reasoning\n",
    "        max_tokens (int): Maximum tokens for the response\n",
    "        \n",
    "    Returns:\n",
    "        dict: The full API response\n",
    "    \"\"\"\n",
    "    # Create a more descriptive system prompt that explains the available tools\n",
    "    tool_descriptions = \"\\n\".join([\n",
    "        f\"- {tool['toolSpec']['name']}: {tool['toolSpec']['description']}\" \n",
    "        for tool in tools\n",
    "    ])\n",
    "    \n",
    "    system_prompt = [{\n",
    "        \"text\": f\"\"\"You're a helpful AI assistant with the ability to use tools.\n",
    "        \n",
    "You have access to the following tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "When a user's request requires using one of these tools:\n",
    "1. First think through what information you need and which tool would be appropriate\n",
    "2. Then provide a clear explanation to the user about your approach\n",
    "3. Finally use the appropriate tool by including the necessary parameters\n",
    "\n",
    "Important: If a question requires calculation, getting weather data, or searching for information,\n",
    "always use the appropriate tool rather than trying to answer from your knowledge.\"\"\"\n",
    "    }]\n",
    "    \n",
    "    # Create messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Base request parameters\n",
    "    request_params = {\n",
    "        \"modelId\": CLAUDE_37_SONNET_MODEL_ID,\n",
    "        \"messages\": messages,\n",
    "        \"system\": system_prompt,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": 1.0,  # Must be 1.0 when reasoning is enabled\n",
    "            \"maxTokens\": max(reasoning_budget + 1, max_tokens)\n",
    "        },\n",
    "        \"additionalModelRequestFields\": {\n",
    "            \"reasoning_config\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": reasoning_budget\n",
    "            }\n",
    "        },\n",
    "        \"toolConfig\": {\n",
    "            \"tools\": tools\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Invoke the model\n",
    "    start_time = time.time()\n",
    "    response = bedrock_runtime.converse(**request_params)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Add elapsed time to response for reference\n",
    "    response[\"_elapsed_time\"] = elapsed_time\n",
    "    \n",
    "    # Debug: print the raw response structure to help diagnose parsing issues\n",
    "    print(\"Response structure:\")\n",
    "    print(f\"Keys in response: {list(response.keys())}\")\n",
    "    if 'output' in response:\n",
    "        print(f\"Keys in response['output']: {list(response['output'].keys())}\")\n",
    "        if 'message' in response['output']:\n",
    "            print(f\"Keys in response['output']['message']: {list(response['output']['message'].keys())}\")\n",
    "            if 'toolUses' in response['output']['message']:\n",
    "                print(f\"Number of tool uses: {len(response['output']['message']['toolUses'])}\")\n",
    "            else:\n",
    "                print(\"No 'toolUses' key found in message\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "def process_tool_outputs(tool_responses):\n",
    "    \"\"\"\n",
    "    Process tool outputs for display\n",
    "    \n",
    "    Args:\n",
    "        tool_responses (list): List of tool responses\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted display of tool responses\n",
    "    \"\"\"\n",
    "    if not tool_responses:\n",
    "        return \"No tool calls made.\"\n",
    "    \n",
    "    output = \"### Tool Results\\n\\n\"\n",
    "    for i, response in enumerate(tool_responses, 1):\n",
    "        output += f\"**Tool Call {i}: {response['tool_name']}**\\n\\n\"\n",
    "        output += f\"Input: `{json.dumps(response['tool_input'])}`\\n\\n\"\n",
    "        if \"error\" in response[\"tool_output\"]:\n",
    "            output += f\"Error: {response['tool_output']['error']}\\n\\n\"\n",
    "        else:\n",
    "            output += f\"Output: `{json.dumps(response['tool_output'], indent=2)}`\\n\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def display_claude_tool_response(response):\n",
    "    \"\"\"\n",
    "    Display Claude's response with detailed tool calls and results\n",
    "    \n",
    "    Args:\n",
    "        response (dict): The API response from Claude\n",
    "    \"\"\"\n",
    "    # Extract metrics\n",
    "    elapsed_time = response.get('_elapsed_time', 0)\n",
    "    input_tokens = response.get('usage', {}).get('inputTokens', 0)\n",
    "    output_tokens = response.get('usage', {}).get('outputTokens', 0)\n",
    "    total_tokens = response.get('usage', {}).get('totalTokens', 0)\n",
    "    \n",
    "    input_cost = input_tokens * 0.000003  # $3 per million tokens\n",
    "    output_cost = output_tokens * 0.000015  # $5 per million tokens\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    # Display metrics\n",
    "    display(Markdown(f\"### Response (in {elapsed_time:.2f} seconds)\"))\n",
    "    display(Markdown(f\"**Tokens**: {total_tokens:,} total ({input_tokens:,} input, {output_tokens:,} output)\"))\n",
    "    display(Markdown(f\"**Estimated cost**: ${total_cost:.5f}\"))\n",
    "    \n",
    "    # Extract the text response\n",
    "    result_text = \"No response content found\"\n",
    "    if response.get('output', {}).get('message', {}).get('content'):\n",
    "        content_blocks = response['output']['message']['content']\n",
    "        for block in content_blocks:\n",
    "            if 'text' in block:\n",
    "                result_text = block['text']\n",
    "                break\n",
    "    \n",
    "    # Display Claude's response\n",
    "    display(Markdown(\"### Claude's Response:\"))\n",
    "    display(Markdown(result_text))\n",
    "    \n",
    "    # Extract tool calls if any\n",
    "    tool_calls = []\n",
    "    tool_responses = []\n",
    "    \n",
    "    # Look for tool calls in the response\n",
    "    message = response.get('output', {}).get('message', {})\n",
    "    \n",
    "    # Check for potential alternative ways tool use might be structured in the response\n",
    "    tool_uses = message.get('toolUses', [])\n",
    "    if not tool_uses and 'content' in message:\n",
    "        # Look for potential tool use blocks in content\n",
    "        for block in message['content']:\n",
    "            if 'toolUse' in block:\n",
    "                display(Markdown(\"\\n**Note**: Found tool use in content block instead of toolUses\"))\n",
    "                # Extract information from the content block\n",
    "                tool_use_block = block['toolUse']\n",
    "                tool_name = tool_use_block.get('name', 'Unknown tool')\n",
    "                tool_input = tool_use_block.get('input', {})\n",
    "                tool_id = tool_use_block.get('toolUseId', 'unknown-id')\n",
    "                \n",
    "                tool_uses.append({\n",
    "                    'name': tool_name,\n",
    "                    'input': tool_input,\n",
    "                    'toolUseId': tool_id\n",
    "                })\n",
    "    \n",
    "    if tool_uses:\n",
    "        # Display detailed tool call information\n",
    "        display(Markdown(\"\\n### ğŸ› ï¸ Tool Calls Details\"))\n",
    "        \n",
    "        for i, tool_use in enumerate(tool_uses, 1):\n",
    "            tool_name = tool_use.get('name', 'Unknown tool')\n",
    "            tool_input = tool_use.get('input', {})\n",
    "            tool_id = tool_use.get('toolUseId', 'unknown-id')\n",
    "            \n",
    "            # Format the JSON input with proper indentation for better readability\n",
    "            formatted_input = json.dumps(tool_input, indent=2)\n",
    "            \n",
    "            # Display detailed tool information in a code block\n",
    "            display(Markdown(f\"#### Tool Call {i}: `{tool_name}`\"))\n",
    "            display(Markdown(f\"**Tool ID**: `{tool_id}`\"))\n",
    "            display(Markdown(\"**JSON Input**:\"))\n",
    "            display(Markdown(f\"```json\\n{formatted_input}\\n```\"))\n",
    "            \n",
    "            # Process the tool call\n",
    "            tool_output = handle_tool_call(tool_name, tool_input)\n",
    "            \n",
    "            # Format the tool output\n",
    "            if isinstance(tool_output, dict):\n",
    "                formatted_output = json.dumps(tool_output, indent=2)\n",
    "                display(Markdown(\"**Tool Output**:\"))\n",
    "                display(Markdown(f\"```json\\n{formatted_output}\\n```\"))\n",
    "            else:\n",
    "                display(Markdown(f\"**Tool Output**: {tool_output}\"))\n",
    "            \n",
    "            # Add to our tracking lists\n",
    "            tool_calls.append({\n",
    "                \"tool_name\": tool_name,\n",
    "                \"tool_input\": tool_input,\n",
    "                \"tool_id\": tool_id\n",
    "            })\n",
    "            \n",
    "            tool_responses.append({\n",
    "                \"tool_name\": tool_name,\n",
    "                \"tool_input\": tool_input,\n",
    "                \"tool_output\": tool_output,\n",
    "                \"tool_id\": tool_id\n",
    "            })\n",
    "    else:\n",
    "        display(Markdown(\"\\n### No Tool Calls Found in Response\"))\n",
    "        display(Markdown(\"Note: This might indicate that either:\"))\n",
    "        display(Markdown(\"1. Claude chose not to use any tools for this query\"))\n",
    "        display(Markdown(\"2. There's an issue with how tool calls are structured in the response\"))\n",
    "        \n",
    "        # Print more details about the response structure to help diagnose issues\n",
    "        if 'output' in response and 'message' in response['output']:\n",
    "            message_keys = list(response['output']['message'].keys())\n",
    "            display(Markdown(f\"Message keys available: {message_keys}\"))\n",
    "    \n",
    "    return {\n",
    "        \"text_response\": result_text,\n",
    "        \"tool_calls\": tool_calls,\n",
    "        \"tool_responses\": tool_responses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0178e9-780d-435d-b1f1-42dd18333d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very explicit prompt that should require tool use\n",
    "explicit_tool_prompt = \"\"\"\n",
    "Please calculate 1234 * 5678 using the calculator tool.\n",
    "Do not try to calculate this yourself - use the calculator tool.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke Claude with the updated functions\n",
    "calculator_response = invoke_claude_with_tools(\n",
    "    explicit_tool_prompt,\n",
    "    [calculator_tool],\n",
    "    reasoning_budget=2048\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "calculator_results = display_claude_tool_response(calculator_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24804723-03b6-48ce-99a7-a35e304ec48e",
   "metadata": {},
   "source": [
    "## æ‹¡å¼µæ€è€ƒã«ã‚ˆã‚‹åŸºæœ¬çš„ãªãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã®å®Ÿè£…\n",
    "\n",
    "æ‹¡å¼µæ€è€ƒã®å¾Œã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã„ã†åŸºæœ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ç°¡å˜ãªä¾‹ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚Claude ã«æ¨è«–ã¨è¨ˆç®—ã®ä¸¡æ–¹ã‚’å¿…è¦ã¨ã™ã‚‹å•é¡Œã‚’ä¸ãˆã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff28c5-d42c-4fa3-a34c-3efeec2b7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example: Calculate compound interest\n",
    "compound_interest_prompt = \"\"\"\n",
    "I need to calculate how much money I'll have if I invest $10,000 for 5 years\n",
    "at an annual interest rate of 7%, compounded quarterly.\n",
    "\n",
    "First explain the compound interest formula and how to apply it in this case,\n",
    "then use the calculator tool to perform the calculation.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke Claude with the calculator tool\n",
    "calculator_response = invoke_claude_with_tools(\n",
    "    compound_interest_prompt,\n",
    "    [calculator_tool],\n",
    "    reasoning_budget=2048\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "calculator_results = display_claude_tool_response(calculator_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebb145-7311-47cb-8bd3-2616aee3e99d",
   "metadata": {},
   "source": [
    "#### åˆ¥ã®ä¾‹ã‚’è¿½åŠ ã—ã¦ã¿ã¾ã—ã‚‡ã†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15bdfc-f2fc-46c0-af90-4f03f389b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Weather comparison\n",
    "weather_prompt = \"\"\"\n",
    "I'm trying to decide whether to vacation in Paris, France or Tokyo, Japan next month.\n",
    "Can you compare the current weather conditions in both cities and give me your recommendation?\n",
    "Please consider temperature, weather conditions, and humidity in your analysis.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke Claude with the weather tool\n",
    "weather_response = invoke_claude_with_tools(\n",
    "    weather_prompt,\n",
    "    [weather_tool],\n",
    "    reasoning_budget=2048\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "weather_results = display_claude_tool_response(weather_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a165da8-d381-4e9a-88e1-e943c74abeb3",
   "metadata": {},
   "source": [
    "## ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³ ãƒã‚¤ãƒ³ãƒˆ: åŸºæœ¬çš„ãªãƒ„ãƒ¼ãƒ«ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "\n",
    "å‰ã®ä¾‹ã§ Claude ãŒãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ–¹æ³•ã«ã¤ã„ã¦ã€ä½•ã«æ°—ä»˜ãã¾ã—ãŸã‹?\n",
    "\n",
    "1. Claude ã¯æœ€åˆã«æ‹¡å¼µæ€è€ƒã‚’ä½¿ç”¨ã—ã¦å•é¡Œã‚’åˆ†æã—ã¾ã—ãŸ (å‡ºåŠ›ã«ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ãŒã€èˆå°è£ã§è¡Œã‚ã‚Œã¦ã„ã¾ã™)\n",
    "\n",
    "2. æ¬¡ã«ã€ãã®æ¨è«–ã¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èª¬æ˜ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’æä¾›ã—ã¾ã—ãŸ\n",
    "\n",
    "3. æœ€å¾Œã«ã€å¿…è¦ãªæƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¡Œã„ã¾ã—ãŸ\n",
    "\n",
    "4. ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¯ã€æ¨è«–ã«åŸºã¥ã„ã¦ç„¦ç‚¹ãŒçµã‚‰ã‚Œã€å…·ä½“çš„ã§ã—ãŸ\n",
    "\n",
    "ã“ã®é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€æ¬¡ã®ç†ç”±ã§å¼·åŠ›ã§ã™:\n",
    "\n",
    "- æ‹¡å¼µæ€è€ƒã«ã‚ˆã‚Šã€Claude ã¯å¿…è¦ãªæƒ…å ±ã‚’ç†è§£ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™\n",
    "- ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¯ã€ã‚ˆã‚Šç„¦ç‚¹ãŒçµã‚‰ã‚Œã€é–¢é€£æ€§ãŒã‚ã‚Šã¾ã™\n",
    "- æ¨è«–ã«ã‚ˆã‚Šã€ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã«é–¢ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨èª¬æ˜ãŒæä¾›ã•ã‚Œã¾ã™\n",
    "\n",
    "ã§ã¯ã€è¤‡æ•°ã®æ¨è«–ã¨ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ„ã¿åˆã‚ã›ãŸã€ã‚ˆã‚Šè¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«é€²ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70866680-5cc2-425a-8b01-9f849b850071",
   "metadata": {},
   "source": [
    "## ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰\n",
    "\n",
    "å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€å¤šãã®å ´åˆã€è¤‡æ•°ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨è«–ã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ãŒå¿…è¦ã§ã™ã€‚æ¬¡ã®ã‚‚ã®ã‚’çµ„ã¿åˆã‚ã›ãŸãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "1. å•é¡Œã«ã¤ã„ã¦ã®æœ€åˆã®æ¨è«–\n",
    "2. æƒ…å ±ã‚’åé›†ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—\n",
    "3. ãƒ„ãƒ¼ãƒ«ã®çµæœã‚’åˆ†æã™ã‚‹ãŸã‚ã®ã•ã‚‰ãªã‚‹æ¨è«–\n",
    "4. ãã®åˆ†æã«åŸºã¥ãè¿½åŠ ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—\n",
    "\n",
    "ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªå•é¡Œã«å¯¾å‡¦ã§ãã‚‹ã€ã‚ˆã‚Šå‹•çš„ã§å¼·åŠ›ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒä½œæˆã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5383e02-db7a-40e2-a467-62535248f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_step_workflow(initial_prompt, tools, max_steps=3):\n",
    "    \"\"\"\n",
    "    Run a multi-step workflow with reasoning and tool use\n",
    "    \n",
    "    Args:\n",
    "        initial_prompt (str): The initial user prompt\n",
    "        tools (list): List of tools to make available\n",
    "        max_steps (int): Maximum number of conversation turns\n",
    "        \n",
    "    Returns:\n",
    "        list: The conversation history\n",
    "    \"\"\"\n",
    "    conversation = []\n",
    "    current_prompt = initial_prompt\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        print(f\"\\n--- Step {step+1} of {max_steps} ---\\n\")\n",
    "        \n",
    "        # Invoke Claude with the current prompt\n",
    "        response = invoke_claude_with_tools(\n",
    "            current_prompt,\n",
    "            tools,\n",
    "            reasoning_budget=4096\n",
    "        )\n",
    "        \n",
    "        # Display the response\n",
    "        results = display_claude_tool_response(response)\n",
    "        conversation.append({\n",
    "            \"prompt\": current_prompt,\n",
    "            \"response\": response,\n",
    "            \"results\": results\n",
    "        })\n",
    "        \n",
    "        # Check if tool calls were made\n",
    "        if not results[\"tool_calls\"]:\n",
    "            print(\"\\nNo tool calls made. Workflow complete.\")\n",
    "            break\n",
    "        \n",
    "        # Process tool results and create the next prompt\n",
    "        tool_summary = \"\\n\\nHere are the results from the tools you used:\\n\\n\"\n",
    "        for tool_response in results[\"tool_responses\"]:\n",
    "            formatted_output = json.dumps(tool_response['tool_output'], indent=2)\n",
    "            tool_summary += f\"- {tool_response['tool_name']} tool returned:\\n```json\\n{formatted_output}\\n```\\n\\n\"\n",
    "        \n",
    "        current_prompt = f\"\"\"\n",
    "        Thank you for your previous response. Here are the results from the tools you used:\n",
    "        \n",
    "        {tool_summary}\n",
    "        \n",
    "        Based on these results, please continue your analysis. You may use the tools again if needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ask if the user wants to continue to the next step\n",
    "        if step < max_steps - 1:\n",
    "            print(\"\\nContinuing to next step...\\n\")\n",
    "    \n",
    "    print(\"\\nWorkflow complete.\")\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3d490-bba8-40ee-a499-13b695505edc",
   "metadata": {},
   "source": [
    "#### æ¬¡ã«ã€ã“ã‚Œã‚’è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®èª¿æŸ»ã®ä¾‹ã«ä½¿ç”¨ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a8ce9-740f-496c-8a36-dea87317827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step research example\n",
    "research_prompt = \"\"\"\n",
    "I'm doing research on the impacts of climate change on agriculture.\n",
    "\n",
    "Please help me gather information about:\n",
    "1. Basic facts about climate change and its main causes\n",
    "2. Specific impacts on agricultural productivity\n",
    "3. Calculate approximately how much global crop yields might decrease if temperatures rise by 2Â°C\n",
    "\n",
    "Use tools as needed to get this information.\n",
    "\"\"\"\n",
    "\n",
    "# Run the multi-step workflow\n",
    "research_conversation = run_multi_step_workflow(\n",
    "    research_prompt,\n",
    "    [calculator_tool, wikipedia_tool],\n",
    "    max_steps=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69de38-1c26-4eed-9a97-80a9b4096581",
   "metadata": {},
   "source": [
    "## ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³ ãƒã‚¤ãƒ³ãƒˆ: ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n",
    "\n",
    "ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¾‹ã§ã¯ã€Claude ãŒæ¬¡ã®æ“ä½œã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã§ãã¾ã—ãŸã€‚\n",
    "\n",
    "1. åŸºæœ¬çš„ãªæƒ…å ±ã‚’åé›†ã™ã‚‹ãŸã‚ã«æœ€åˆã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¡Œã†\n",
    "2. ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã®çµæœã‚’å‡¦ç†ã™ã‚‹\n",
    "3. æ–°ã—ã„æƒ…å ±ã«åŸºã¥ã„ã¦è¿½åŠ ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¡Œã†\n",
    "4. è¤‡æ•°ã®ã‚¿ãƒ¼ãƒ³ã«ã‚ãŸã£ã¦åŒ…æ‹¬çš„ãªå¿œç­”ã‚’æ§‹ç¯‰ã™ã‚‹\n",
    "\n",
    "ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€æ¬¡ã®ã‚ˆã†ãªè¤‡é›‘ãªèª¿æŸ»ãŠã‚ˆã³åˆ†æã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã§ã™ã€‚\n",
    "- è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’åé›†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹\n",
    "- è¨ˆç®—ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒå¿…è¦\n",
    "- ä»¥å‰ã®èª¿æŸ»çµæœã«åŸºã¥ã„ã¦é€£ç¶šã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã‚’æ§‹ç¯‰ã™ã‚‹\n",
    "\n",
    "ãŸã ã—ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¯èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚\n",
    "- è¤‡æ•°ã®ã‚¿ãƒ¼ãƒ³ã«ã‚ãŸã£ã¦ä¼šè©±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç®¡ç†ã™ã‚‹\n",
    "- ä½¿ç”¨ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã¨åé›†ã•ã‚ŒãŸæƒ…å ±ã‚’è¿½è·¡ã™ã‚‹\n",
    "- æ½œåœ¨çš„ãªã‚¨ãƒ©ãƒ¼ã‚„ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã‚’å‡¦ç†ã™ã‚‹\n",
    "\n",
    "æ¬¡ã«ã€ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã€ã‚ˆã‚Šå …ç‰¢ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87470dd-8928-4e37-aa0b-846aead0b36f",
   "metadata": {},
   "source": [
    "## ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨å›å¾©æˆ¦ç•¥\n",
    "\n",
    "æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€ã•ã¾ã–ã¾ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "1. **ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼**: ãƒ„ãƒ¼ãƒ«ãŒå¤±æ•—ã—ãŸã‚Šã€äºˆæœŸã—ãªã„çµæœãŒè¿”ã•ã‚ŒãŸã‚Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n",
    "2. **æ¨è«–ã‚¨ãƒ©ãƒ¼**: ã‚¯ãƒ­ãƒ¼ãƒ‰ãŒå•é¡Œã¾ãŸã¯ãƒ„ãƒ¼ãƒ«ã®çµæœã‚’èª¤ã£ã¦è§£é‡ˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n",
    "3. **èª¿æ•´ã‚¨ãƒ©ãƒ¼**: æ¨è«–ã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã®é †åºãŒåŒæœŸã—ãªããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n",
    "\n",
    "ã“ã‚Œã‚‰ã®ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã€ã‚ˆã‚Šå …ç‰¢ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’ã„ãã¤ã‹å®Ÿè£…ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb413fff-6f90-4733-8076-5c94d9adfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_claude_with_error_handling(prompt, tools, reasoning_budget=4096, max_retries=2):\n",
    "    \"\"\"\n",
    "    Invoke Claude with extended thinking and tool use, with error handling\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        tools (list): List of tools to make available\n",
    "        reasoning_budget (int): Token budget for reasoning\n",
    "        max_retries (int): Maximum number of retry attempts for tool errors\n",
    "        \n",
    "    Returns:\n",
    "        dict: Results including the response and any error information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First attempt\n",
    "        response = invoke_claude_with_tools(\n",
    "            prompt,\n",
    "            tools,\n",
    "            reasoning_budget=reasoning_budget\n",
    "        )\n",
    "        \n",
    "        # Display the initial response\n",
    "        results = display_claude_tool_response(response)\n",
    "        \n",
    "        # Check for tool errors\n",
    "        tool_errors = []\n",
    "        for tool_response in results.get(\"tool_responses\", []):\n",
    "            if isinstance(tool_response.get(\"tool_output\", {}), dict) and \"error\" in tool_response.get(\"tool_output\", {}):\n",
    "                tool_errors.append({\n",
    "                    \"tool_name\": tool_response[\"tool_name\"],\n",
    "                    \"error\": tool_response[\"tool_output\"][\"error\"],\n",
    "                    \"input\": tool_response[\"tool_input\"]\n",
    "                })\n",
    "        \n",
    "        # If there are tool errors, attempt recovery\n",
    "        retry_count = 0\n",
    "        while tool_errors and retry_count < max_retries:\n",
    "            retry_count += 1\n",
    "            print(f\"\\n--- Retry attempt {retry_count} for tool errors ---\\n\")\n",
    "            \n",
    "            # Create a prompt explaining the errors\n",
    "            error_prompt = f\"\"\"\n",
    "            There were some issues with the tools you tried to use:\n",
    "            \n",
    "            {json.dumps(tool_errors, indent=2)}\n",
    "            \n",
    "            Please try again with different approaches or parameters. Here was the original request:\n",
    "            \n",
    "            {prompt}\n",
    "            \"\"\"\n",
    "            \n",
    "            # Retry with the error information\n",
    "            retry_response = invoke_claude_with_tools(\n",
    "                error_prompt,\n",
    "                tools,\n",
    "                reasoning_budget=reasoning_budget\n",
    "            )\n",
    "            \n",
    "            # Display the retry response\n",
    "            retry_results = display_claude_tool_response(retry_response)\n",
    "            \n",
    "            # Check if errors were resolved\n",
    "            new_tool_errors = []\n",
    "            for tool_response in retry_results.get(\"tool_responses\", []):\n",
    "                if isinstance(tool_response.get(\"tool_output\", {}), dict) and \"error\" in tool_response.get(\"tool_output\", {}):\n",
    "                    new_tool_errors.append({\n",
    "                        \"tool_name\": tool_response[\"tool_name\"],\n",
    "                        \"error\": tool_response[\"tool_output\"][\"error\"],\n",
    "                        \"input\": tool_response[\"tool_input\"]\n",
    "                    })\n",
    "            \n",
    "            # If errors were resolved or reduced, update the results\n",
    "            if len(new_tool_errors) < len(tool_errors):\n",
    "                results = retry_results\n",
    "                tool_errors = new_tool_errors\n",
    "            else:\n",
    "                # If no improvement, stop retrying\n",
    "                break\n",
    "        \n",
    "        # Add error summary to results\n",
    "        results[\"tool_errors\"] = tool_errors\n",
    "        results[\"retry_count\"] = retry_count\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle any unexpected errors\n",
    "        print(f\"Error in invoke_claude_with_error_handling: {str(e)}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"text_response\": f\"An error occurred: {str(e)}\",\n",
    "            \"tool_calls\": [],\n",
    "            \"tool_responses\": [],\n",
    "            \"tool_errors\": [],\n",
    "            \"retry_count\": 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9f33c-c537-4942-a16c-0da8598d07ed",
   "metadata": {},
   "source": [
    "#### ä¾‹ã‚’ä½¿ã£ã¦ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcc493-9829-4648-8b32-b1b7cf86a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with potential errors\n",
    "error_prone_prompt = \"\"\"\n",
    "I want to calculate how much 1,000,000 raised to the power of 100 is.\n",
    "Use the calculator tool to figure this out.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke Claude with error handling\n",
    "error_handling_results = invoke_claude_with_error_handling(\n",
    "    error_prone_prompt,\n",
    "    [calculator_tool],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "# Display error summary\n",
    "if error_handling_results.get(\"tool_errors\"):\n",
    "    print(\"\\n### Error Summary\")\n",
    "    print(f\"Total errors: {len(error_handling_results['tool_errors'])}\")\n",
    "    print(f\"Retry attempts: {error_handling_results['retry_count']}\")\n",
    "    for i, error in enumerate(error_handling_results[\"tool_errors\"], 1):\n",
    "        print(f\"\\nError {i}:\")\n",
    "        print(f\"Tool: {error['tool_name']}\")\n",
    "        print(f\"Input: {error['input']}\")\n",
    "        print(f\"Error: {error['error']}\")\n",
    "else:\n",
    "    print(\"\\nNo tool errors occurred or all errors were resolved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277f714-9e1b-4383-a92f-a281eb3ec093",
   "metadata": {},
   "source": [
    "## åŸºæœ¬çš„ãªãƒªã‚µãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ§‹ç¯‰\n",
    "\n",
    "ã§ã¯ã€ã“ã‚Œã¾ã§ã«å­¦ã‚“ã ã™ã¹ã¦ã®æ¦‚å¿µã‚’çµ„ã¿åˆã‚ã›ã¦ã€æ¬¡ã®ã‚ˆã†ãªã‚·ãƒ³ãƒ—ãƒ«ãªãƒªã‚µãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "1. æ‹¡å¼µæ€è€ƒã‚’ä½¿ç”¨ã—ã¦ãƒªã‚µãƒ¼ãƒ ã‚¯ã‚¨ãƒªã‚’ç†è§£ã™ã‚‹\n",
    "2. é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦æƒ…å ±ã‚’åé›†ã™ã‚‹\n",
    "3. è¿½åŠ ã®æ¨è«–ã‚’ä½¿ç”¨ã—ã¦çµæœã‚’å‡¦ç†ã™ã‚‹\n",
    "4. ã‚¨ãƒ©ãƒ¼ã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹\n",
    "5. åŒ…æ‹¬çš„ãªå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹\n",
    "\n",
    "ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§å¼·åŠ›ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1306038-233b-4d09-8ea9-d259bb9f5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAgent:\n",
    "    \"\"\"\n",
    "    A simple research agent that combines extended thinking with tool use\n",
    "    \"\"\"\n",
    "    def __init__(self, tools=None, reasoning_budget=4096):\n",
    "        \"\"\"\n",
    "        Initialize the research agent\n",
    "        \n",
    "        Args:\n",
    "            tools (list): List of tools available to the agent\n",
    "            reasoning_budget (int): Token budget for reasoning\n",
    "        \"\"\"\n",
    "        self.tools = tools or [calculator_tool, weather_tool, wikipedia_tool]\n",
    "        self.reasoning_budget = reasoning_budget\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def research(self, query, max_steps=3):\n",
    "        \"\"\"\n",
    "        Conduct research on a query\n",
    "        \n",
    "        Args:\n",
    "            query (str): The research query\n",
    "            max_steps (int): Maximum number of conversation turns\n",
    "            \n",
    "        Returns:\n",
    "            dict: The research results\n",
    "        \"\"\"\n",
    "        print(f\"Starting research on: {query}\")\n",
    "        \n",
    "        # Format the initial prompt\n",
    "        initial_prompt = f\"\"\"\n",
    "        You are a research assistant. Please help me research the following topic:\n",
    "        \n",
    "        {query}\n",
    "        \n",
    "        Think carefully about what information you need to gather and which tools would be most helpful.\n",
    "        Develop a research plan, then execute it step by step using the available tools.\n",
    "        \n",
    "        Provide a comprehensive response that synthesizes the information you gather.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Run the multi-step workflow\n",
    "        conversation = run_multi_step_workflow(\n",
    "            initial_prompt,\n",
    "            self.tools,\n",
    "            max_steps=max_steps\n",
    "        )\n",
    "        \n",
    "        # Store the conversation history\n",
    "        self.conversation_history.extend(conversation)\n",
    "        \n",
    "        # Extract the final results\n",
    "        if conversation:\n",
    "            final_step = conversation[-1]\n",
    "            final_response = final_step.get(\"results\", {}).get(\"text_response\", \"No response generated\")\n",
    "            \n",
    "            # Create a summary of all tool calls\n",
    "            tool_calls_summary = []\n",
    "            for step in conversation:\n",
    "                for tool_call in step.get(\"results\", {}).get(\"tool_calls\", []):\n",
    "                    tool_calls_summary.append({\n",
    "                        \"tool\": tool_call[\"tool_name\"],\n",
    "                        \"input\": tool_call[\"tool_input\"]\n",
    "                    })\n",
    "            \n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"steps\": len(conversation),\n",
    "                \"final_response\": final_response,\n",
    "                \"tool_calls\": tool_calls_summary,\n",
    "                \"full_conversation\": conversation\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"steps\": 0,\n",
    "                \"final_response\": \"Research could not be completed\",\n",
    "                \"tool_calls\": [],\n",
    "                \"full_conversation\": []\n",
    "            }\n",
    "    \n",
    "    def summarize_research(self, results):\n",
    "        \"\"\"\n",
    "        Generate a summary of the research results\n",
    "        \n",
    "        Args:\n",
    "            results (dict): The research results\n",
    "            \n",
    "        Returns:\n",
    "            str: A markdown summary of the research\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return \"No research results available.\"\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "        # Research Summary: {results['query']}\n",
    "        \n",
    "        ## Overview\n",
    "        - Research steps: {results['steps']}\n",
    "        - Tools used: {len(results['tool_calls'])}\n",
    "        \n",
    "        ## Tools Used\n",
    "        \"\"\"\n",
    "        \n",
    "        # Group tool calls by tool type\n",
    "        tool_usage = {}\n",
    "        for call in results['tool_calls']:\n",
    "            tool_name = call['tool']\n",
    "            if tool_name not in tool_usage:\n",
    "                tool_usage[tool_name] = []\n",
    "            tool_usage[tool_name].append(call['input'])\n",
    "        \n",
    "        # Add tool usage to summary\n",
    "        for tool_name, calls in tool_usage.items():\n",
    "            summary += f\"\\n### {tool_name.capitalize()}\\n\"\n",
    "            summary += f\"- Used {len(calls)} times\\n\"\n",
    "            for i, call in enumerate(calls[:3], 1):  # Show up to 3 examples\n",
    "                summary += f\"- Example {i}: `{json.dumps(call)}`\\n\"\n",
    "            if len(calls) > 3:\n",
    "                summary += f\"- ...and {len(calls) - 3} more\\n\"\n",
    "        \n",
    "        # Add the final response\n",
    "        summary += f\"\\n## Final Response\\n\\n{results['final_response']}\\n\"\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceed096-afad-45c7-b3ae-3d5d57e7cab2",
   "metadata": {},
   "source": [
    "#### ã§ã¯ã€ãƒªã‚µãƒ¼ãƒã‚¯ã‚¨ãƒªã‚’ä½¿ã£ã¦ ResearchAgent ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b7481-735e-4d38-a768-4fe5ff09aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a research agent with our tools\n",
    "agent = ResearchAgent(\n",
    "    tools=[calculator_tool, wikipedia_tool],\n",
    "    reasoning_budget=4096\n",
    ")\n",
    "\n",
    "# Run research on a topic\n",
    "research_results = agent.research(\n",
    "    \"What are the potential economic impacts of artificial intelligence on employment in the next decade?\",\n",
    "    max_steps=2\n",
    ")\n",
    "\n",
    "# Display the research summary\n",
    "research_summary = agent.summarize_research(research_results)\n",
    "display(Markdown(research_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de2b80-8f41-4c8e-ab60-af08f444e5bf",
   "metadata": {},
   "source": [
    "## ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³ ãƒã‚¤ãƒ³ãƒˆ: åŠ¹æœçš„ãªãƒªã‚µãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ§‹ç¯‰\n",
    "\n",
    "å½“ç¤¾ã®ãƒªã‚µãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®ã„ãã¤ã‹ã®é‡è¦ãªåŸå‰‡ã‚’ç¤ºã—ã¦ã„ã¾ã™:\n",
    "\n",
    "1. **ãƒªã‚µãƒ¼ãƒ ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°**: æ‹¡å¼µæ€è€ƒã‚’ä½¿ç”¨ã—ã¦ä½“ç³»çš„ãªãƒªã‚µãƒ¼ãƒ ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¾ã™\n",
    "2. **ãƒ„ãƒ¼ãƒ«ã®é¸æŠ**: å¿…è¦ãªæƒ…å ±ã«åŸºã¥ã„ã¦é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã—ã¾ã™\n",
    "3. **ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: è¤‡æ•°ã®ä¼šè©±ã‚¿ãƒ¼ãƒ³ã«ã‚ãŸã£ã¦çŸ¥è­˜ã‚’æ§‹ç¯‰ã—ã¾ã™\n",
    "4. **æƒ…å ±ã®çµ±åˆ**: ã•ã¾ã–ã¾ãªã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®æƒ…å ±ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ä¸€è²«ã—ãŸå¿œç­”ã‚’ä½œæˆã—ã¾ã™\n",
    "\n",
    "ã‚ˆã‚Šé«˜åº¦ãªãƒªã‚µãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã«ã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¬¡ã®æ–¹æ³•ã§æ‹¡å¼µã§ãã¾ã™:\n",
    "\n",
    "- ã‚ˆã‚Šå°‚é–€çš„ãªãƒ„ãƒ¼ãƒ« (ä¾‹: ãƒ‡ãƒ¼ã‚¿åˆ†æã€è¦–è¦šåŒ–)\n",
    "- ä¼šè©±ã‚¿ãƒ¼ãƒ³å…¨ä½“ã«ã‚ãŸã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã®æ”¹å–„\n",
    "- ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼å‡¦ç†ãŠã‚ˆã³å›å¾©æˆ¦ç•¥\n",
    "- éå»ã®ãƒªã‚µãƒ¼ãƒã‹ã‚‰å­¦ç¿’ã—ã¦å°†æ¥ã®ã‚¯ã‚¨ãƒªã‚’æ”¹å–„ã—ã¾ã™\n",
    "\n",
    "æ‹¡å¼µæ€è€ƒã®å¾Œã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã„ã†ã‚³ã‚¢ ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€ã“ã‚Œã‚‰ã®ã‚ˆã‚Šé«˜åº¦ãªæ©Ÿèƒ½ã®å¼·åŠ›ãªåŸºç›¤ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4cb5d7-02f9-44cc-ae40-8e25f505c7ea",
   "metadata": {},
   "source": [
    "## çµè«–: æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹åŠ›\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Claude 3.7 Sonnet ã®æ‹¡å¼µæ€è€ƒèƒ½åŠ›ã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’åŠ¹æœçš„ã«çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã‚’æ¤œè¨ã—ã¾ã—ãŸã€‚ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™:\n",
    "\n",
    "1. **ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ« ãƒ‘ã‚¿ãƒ¼ãƒ³**: Claude ã¯ã¾ãšå•é¡Œã«ã¤ã„ã¦æ¨è«–ã—ã€æ¬¡ã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’åé›†ã—ãŸã‚Šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ãŸã‚Šã—ã¾ã™\n",
    "2. **ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: è¤‡é›‘ãªå•é¡Œã¯ã€æ¨è«–ã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—è¡Œã†ã“ã¨ã§è§£æ±ºã§ãã¾ã™\n",
    "3. **ã‚¨ãƒ©ãƒ¼å‡¦ç†**: å …ç‰¢ãªèª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯ã€ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã¦å•é¡Œã‹ã‚‰å›å¾©ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ãŒå¿…è¦ã§ã™\n",
    "4. **èª¿æŸ»è¨ˆç”»**: æ‹¡å¼µæ€è€ƒã«ã‚ˆã‚Šã€Claude ã¯ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ä½“ç³»çš„ãªèª¿æŸ»è¨ˆç”»ã‚’ä½œæˆã§ãã¾ã™\n",
    "\n",
    "ã“ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€äººé–“ãŒè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å–ã‚Šçµ„ã‚€æ–¹æ³•ã‚’æ¨¡å€£ã—ãŸå¼·åŠ›ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒä½œæˆã•ã‚Œã¾ã™:\n",
    "- æœ€åˆã«å¿…è¦ãªæƒ…å ±ã‚’æ¤œè¨ã—ã¾ã™\n",
    "- æ¬¡ã«ã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã®æƒ…å ±ã‚’åé›†ã—ã¾ã™\n",
    "- æœ€å¾Œã«ã€æƒ…å ±ã‚’ç·åˆçš„ã«çµ±åˆã—ã¦åŒ…æ‹¬çš„ãªå¿œç­”ã‚’ä½œæˆã—ã¾ã™\n",
    "\n",
    "Claude 3.7 Sonnet ã‚’ä½¿ç”¨ã—ã¦ç‹¬è‡ªã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã¨ãã¯ã€ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ã¦ã€ã‚ˆã‚Šã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã§é©å¿œæ€§ã«å„ªã‚Œã€ä¾¿åˆ©ãª AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’ã•ã‚‰ã«æ¢æ±‚ã™ã‚‹ã«ã¯ã€æ¬¡ã®ç‚¹ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "1. ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«åˆã‚ã›ã¦èª¿æ•´ã•ã‚ŒãŸ **ã‚ˆã‚Šå°‚é–€çš„ãªãƒ„ãƒ¼ãƒ«ã®è¿½åŠ **\n",
    "2. **ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼å‡¦ç†** æˆ¦ç•¥ã®å®Ÿè£…\n",
    "3. ã•ã¾ã–ã¾ãªã‚¿ã‚¤ãƒ—ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ **ç•°ãªã‚‹æ¨è«–äºˆç®—ã®å®Ÿé¨“**\n",
    "4. ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹å‘ã‘ã« **ã‚ˆã‚Šè¤‡é›‘ãªãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰**\n",
    "\n",
    "æ‹¡å¼µæ€è€ƒã¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªç¾å®Ÿã®å•é¡Œã«å¯¾å‡¦ã§ãã‚‹ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹ãŸã‚ã®å¹…åºƒã„å¯èƒ½æ€§ãŒé–‹ã‹ã‚Œã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
