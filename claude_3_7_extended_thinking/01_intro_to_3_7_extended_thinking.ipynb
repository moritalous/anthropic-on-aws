{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a36d098-0dd7-4a60-9fa4-df879a893cf2",
   "metadata": {},
   "source": [
    "# Claude 3.7 Sonnet と拡張思考の紹介\n",
    "\n",
    "このノートブックでは、Anthropic の Claude 3.7 Sonnet モデルとその革新的な「拡張思考」機能について紹介します。次の内容について説明します。\n",
    "\n",
    "1. Claude 3.7 Sonnet の機能の概要\n",
    "2. 拡張思考とその仕組みの理解\n",
    "3. Amazon Bedrock での Claude 3.7 のセットアップ\n",
    "4. 標準モードと拡張思考モードの比較\n",
    "5. 思考プロセスの視覚化\n",
    "\n",
    "このノートブックを読み終えると、拡張思考を使用して AI ワークフローを改善するタイミングと方法を明確に理解できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62af895-abaa-473d-944a-d0db857bbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -qU --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165fa07-26e3-4343-9f53-7f5f9b7d62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4ea05-3d2e-4326-88d0-92edef095d97",
   "metadata": {},
   "source": [
    "## 1. Claude 3.7 Sonnet の機能の概要\n",
    "\n",
    "Claude 3.7 Sonnet は、2025 年 2 月にリリースされた Anthropic のこれまでで最も高度なモデルです。以前の Claude モデルに比べていくつかの重要な改善が導入されています:\n",
    "\n",
    "### 主な機能\n",
    "\n",
    "- **ハイブリッド推論アプローチ**: Claude 3.7 Sonnet は標準モードと「拡張思考」モードの両方で動作できるため、モデルがより深い推論を行うタイミングを制御できます。\n",
    "\n",
    "- **出力長の増加**: 最大 64K の出力トークン (以前のモデルの 8 倍の長さ) をサポートし、プレビューでは最大 128K のトークンがサポートされています。\n",
    "\n",
    "- **コンピューターの使用強化**: スクロール、待機、マウスの左下/上、キーのホールド、トリプルクリックなどの追加アクションを含む、コンピューター操作の機能が向上しました。\n",
    "\n",
    "- **コード生成の改善**: コーディング ベンチマーク、特に SWE-bench Verified でトップクラスのパフォーマンスを発揮します。\n",
    "\n",
    "- **推論予算の制御**: API を使用すると、タスクに割り当てる「思考力」の量を正確に制御できます。必要な最小限の予算から、複雑な問題に対するはるかに大きな割り当てまで、さまざまな方法で制御できます。\n",
    "\n",
    "Claude 3.7 Sonnet は、詳細な分析、複雑な問題解決、および複数ステップの推論を必要とするタスクに優れています。また、長時間の思考が必要ない場合は、迅速な応答を提供する機能も維持しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74121f3-55e7-4e44-b02a-41e7843af7a3",
   "metadata": {},
   "source": [
    "## 2. 拡張思考を理解する\n",
    "\n",
    "### 拡張思考とは何ですか?\n",
    "\n",
    "拡張思考は、ユーザーに表示できる段階的な推論を通じて、クロードが複雑な問題を解決できる画期的な機能です。最終的な答えを見るのではなく、数学者がホワイトボード上で証明を進めていくのを見ているようなものだと考えてください。\n",
    "\n",
    "### 拡張思考の仕組み\n",
    "\n",
    "Claude 3.7 Sonnet を有効にすると、人間の問題解決に似たプロセスが実行されます:\n",
    "\n",
    "1. 最初にタスクを内部の「スクラッチパッド」で処理します - 問題を段階的に考えます\n",
    "2. この推論プロセスは、API 応答で確認できます\n",
    "3. 推論を完了すると、Claude はこの思考に基づいて最終的な回答を提供します\n",
    "\n",
    "### 拡張思考と思考の連鎖\n",
    "\n",
    "**従来の思考の連鎖 (CoT):**\n",
    "- 段階的な推論を引き出すには、特定のプロンプトが必要です\n",
    "- 推論の品質はプロンプト エンジニアリングに大きく依存します\n",
    "- 推論と応答が混在しています\n",
    "- 推論の深さを制御できません\n",
    "\n",
    "**拡張思考:**\n",
    "- API パラメーターによって明示的に有効になります\n",
    "- 推論の予算を正確に制御できます\n",
    "- 推論は、最終応答とは別のフィールドに表示されます\n",
    "- より徹底的で構造化された推論\n",
    "\n",
    "### 推論の予算\n",
    "\n",
    "Claude の重要な革新3.7 Sonnet は、「推論予算」を制御する機能です。これは、思考プロセスに割り当てられるトークンの量です。\n",
    "\n",
    "- 最小予算: 1,024 トークン\n",
    "- モデルの 128K トークン制限まで増やすことができます\n",
    "- 予算が大きいほど、複雑な問題に対するより徹底した推論が可能になります\n",
    "\n",
    "推論予算は、計算タスクに CPU 時間を割り当てるようなものと考えてください。より複雑なタスクほど、割り当てが大きいほどメリットがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d7a97-436d-4161-bd83-3514d4d00197",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Setting up Claude 3.7 in Amazon Bedrock\n",
    "\n",
    "# Configure the AWS region\n",
    "REGION = 'us-west-2'  # Change to your preferred region\n",
    "config = Config(read_timeout=300)\n",
    "\n",
    "\n",
    "# Initialize Bedrock clients\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    region_name=REGION,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=REGION,\n",
    ")\n",
    "\n",
    "# Claude 3.7 Sonnet model ID\n",
    "CLAUDE_37_SONNET_MODEL_ID = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "\n",
    "# For comparison, Claude 3.5 Sonnet model ID\n",
    "CLAUDE_35_SONNET_MODEL_ID = 'us.anthropic.claude-3-5-sonnet-20241022-v2:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3373568-7a3e-4fd2-9ad7-c2133f32a362",
   "metadata": {},
   "source": [
    "> **注**: このレッスンでは、わかりやすくするために以下の関数を示していますが、今後はこれらのユーティリティ関数を `claude_utils` としてインポートします。`claude_utils.py` モジュールには、Bedrock クライアントを作成し、拡張思考の有無にかかわらず Claude を呼び出し、応答を表示するためのヘルパー関数が含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46d082-9c69-46d2-8727-3c7446c26858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_claude(\n",
    "    prompt, \n",
    "    model_id=CLAUDE_37_SONNET_MODEL_ID, \n",
    "    enable_reasoning=False, \n",
    "    reasoning_budget=1024,\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Invoke Claude with or without extended thinking.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to Claude\n",
    "        model_id (str): The model ID to use\n",
    "        enable_reasoning (bool): Whether to enable extended thinking\n",
    "        reasoning_budget (int): Token budget for reasoning (min 1024)\n",
    "        temperature (float): Temperature for generation (0.0-1.0)\n",
    "        max_tokens (int): Maximum tokens to generate\n",
    "        \n",
    "    Returns:\n",
    "        dict: The complete API response\n",
    "    \"\"\"\n",
    "    # Create system prompt and messages\n",
    "    system_prompt = [{\"text\": \"You're a helpful AI assistant.\"}]\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Base request parameters\n",
    "    request_params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"system\": system_prompt,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"maxTokens\": max_tokens\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add reasoning configuration if enabled\n",
    "    if enable_reasoning:\n",
    "        # When using reasoning, temperature must be 1.0\n",
    "        request_params[\"inferenceConfig\"][\"temperature\"] = 1.0\n",
    "        \n",
    "        # Ensure maxTokens is greater than reasoning_budget\n",
    "        if max_tokens <= reasoning_budget:\n",
    "            # Make it just one token more than the reasoning budget\n",
    "            adjusted_max_tokens = reasoning_budget + 1\n",
    "            print(f\"Info: Increasing maxTokens from {max_tokens} to {adjusted_max_tokens} to exceed reasoning budget\")\n",
    "            request_params[\"inferenceConfig\"][\"maxTokens\"] = adjusted_max_tokens\n",
    "        \n",
    "        request_params[\"additionalModelRequestFields\"] = {\n",
    "            \"reasoning_config\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": reasoning_budget\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Invoke the model\n",
    "    start_time = time.time()\n",
    "    response = bedrock_runtime.converse(**request_params)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Add elapsed time to response for reference\n",
    "    response[\"_elapsed_time\"] = elapsed_time\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def extract_response_content(response):\n",
    "    \"\"\"Extract the response content from Claude's API response\"\"\"\n",
    "    if response.get('output', {}).get('message', {}).get('content'):\n",
    "        content_blocks = response['output']['message']['content']\n",
    "        for block in content_blocks:\n",
    "            if 'text' in block:\n",
    "                return block['text']\n",
    "    return \"No response content found\"\n",
    "\n",
    "def print_section_header(message):\n",
    "    \"\"\"Helper function to print a decorative section header\"\"\"\n",
    "    width = 80\n",
    "    decoration = colored(\"╔\" + \"═\"*(width-2) + \"╗\", \"blue\")\n",
    "    empty_line = colored(\"║\" + \" \"*(width-2) + \"║\", \"blue\")\n",
    "    \n",
    "    # Center the message\n",
    "    message_length = len(message)\n",
    "    padding = (width - 2 - message_length) // 2\n",
    "    message_line = colored(\"║\", \"blue\") + \" \"*padding + colored(message, \"cyan\", attrs=[\"bold\"]) + \" \"*(width - 2 - padding - message_length) + colored(\"║\", \"blue\")\n",
    "    \n",
    "    bottom = colored(\"╚\" + \"═\"*(width-2) + \"╝\", \"blue\")\n",
    "    \n",
    "    print(\"\\n\" + decoration)\n",
    "    print(empty_line)\n",
    "    print(message_line)\n",
    "    print(empty_line)\n",
    "    print(bottom + \"\\n\")\n",
    "\n",
    "def display_claude_response(response, show_reasoning=False):\n",
    "    \"\"\"Display Claude's response in a nicely formatted way with colors\"\"\"\n",
    "    result = extract_response_content(response)\n",
    "    \n",
    "    # Calculate costs (approximate)\n",
    "    input_tokens = response.get('usage', {}).get('inputTokens', 0)\n",
    "    output_tokens = response.get('usage', {}).get('outputTokens', 0)\n",
    "    total_tokens = response.get('usage', {}).get('totalTokens', 0)\n",
    "    \n",
    "    input_cost = input_tokens * 0.000003  # $3 per million tokens\n",
    "    output_cost = output_tokens * 0.000015  # $15 per million tokens\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    # Create styled HTML output\n",
    "    metrics_html = f\"\"\"\n",
    "    <div style=\"background-color: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
    "        <h3 style=\"color: #2c5282; margin-top: 0;\">📊 Response Metrics</h3>\n",
    "        <p style=\"color: #4a5568;\"><strong>⏱️ Time:</strong> {response.get('_elapsed_time', 0):.2f} seconds</p>\n",
    "        <p style=\"color: #4a5568;\"><strong>🔤 Tokens:</strong> {total_tokens:,} total \n",
    "           (<span style=\"color: #38a169;\">{input_tokens:,} input</span>, \n",
    "            <span style=\"color: #805ad5;\">{output_tokens:,} output</span>)</p>\n",
    "        <p style=\"color: #4a5568;\"><strong>💰 Estimated cost:</strong> \n",
    "           <span style=\"color: #e53e3e;\">${total_cost:.5f}</span></p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    response_html = f\"\"\"\n",
    "    <div style=\"background-color: #fff5f5; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
    "        <h3 style=\"color: #2c5282; margin-top: 0;\">🤖 Claude's Response:</h3>\n",
    "        <div style=\"color: #4a5568;\">{result}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Display the formatted output\n",
    "    display(HTML(metrics_html))\n",
    "    display(HTML(response_html))\n",
    "    \n",
    "    # Also print colored console output for non-notebook environments\n",
    "    print(colored(\"\\n=== Response Metrics ===\", \"blue\", attrs=[\"bold\"]))\n",
    "    print(colored(f\"Time: {response.get('_elapsed_time', 0):.2f} seconds\", \"cyan\"))\n",
    "    print(colored(f\"Tokens: {total_tokens:,} total ({input_tokens:,} input, {output_tokens:,} output)\", \"green\"))\n",
    "    print(colored(f\"Estimated cost: ${total_cost:.5f}\", \"yellow\"))\n",
    "    print(colored(\"\\n=== Claude's Response ===\", \"blue\", attrs=[\"bold\"]))\n",
    "    print(colored(result, \"white\"))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72260615-b301-4f83-92ce-1e390a2c4db1",
   "metadata": {},
   "source": [
    "## 4. 標準モードと拡張思考モードの比較\n",
    "\n",
    "では、Claude 3.7 Sonnet の動作を見てみましょう。拡張思考を有効にした場合と有効にしなかった場合のパフォーマンスを比較します。拡張思考がどのような場合に最もメリットをもたらすかを示すために、いくつかの異なるタイプの問題でテストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e7a36-4f70-4fae-9a46-e68a77326719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example - Capital city question\n",
    "simple_prompt = \"What is the capital of France?\"\n",
    "\n",
    "# Without extended thinking\n",
    "print_section_header(\"Calling Claude 3.7 Sonnet WITHOUT extended thinking...\")\n",
    "standard_response = invoke_claude(\n",
    "    simple_prompt,\n",
    "    enable_reasoning=False,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "display_claude_response(standard_response, show_reasoning=False)\n",
    "\n",
    "# With extended thinking\n",
    "print_section_header(\"Calling Claude 3.7 Sonnet WITH extended thinking...\")\n",
    "reasoning_response = invoke_claude(\n",
    "    simple_prompt,\n",
    "    enable_reasoning=True,\n",
    "    reasoning_budget=1024,  # Minimum budget\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "display_claude_response(reasoning_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf8193-6ba1-48cd-9fb1-114f2022bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex example - Sock drawer problem\n",
    "complex_prompt = \"\"\"\n",
    "A man has 53 socks in his drawer: 21 identical blue, 15 identical black and 17 identical red.\n",
    "The lights are out, and he is completely in the dark. How many socks must he take out to make 100 percent\n",
    "certain he has at least one pair of black socks?\n",
    "\"\"\"\n",
    "\n",
    "# Without extended thinking\n",
    "print(\"Calling Claude 3.7 Sonnet WITHOUT extended thinking...\")\n",
    "standard_complex_response = invoke_claude(\n",
    "    complex_prompt,\n",
    "    enable_reasoning=False,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "display_claude_response(standard_complex_response, show_reasoning=False)\n",
    "\n",
    "# With extended thinking\n",
    "print(\"\\nCalling Claude 3.7 Sonnet WITH extended thinking...\")\n",
    "reasoning_complex_response = invoke_claude(\n",
    "    complex_prompt,\n",
    "    enable_reasoning=True,\n",
    "    reasoning_budget=2048,  # A bit more budget for this problem\n",
    "    max_tokens=2049  # Ensuring it's at least 1 token more than the reasoning budget\n",
    ")\n",
    "\n",
    "display_claude_response(reasoning_complex_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c98b46-f5ce-454e-ab57-02f3ac825823",
   "metadata": {},
   "source": [
    "## 5. 異なる推論予算のパフォーマンス分析\n",
    "\n",
    "では、異なる推論予算が靴下引き出し問題における Claude のパフォーマンスにどのように影響するかを体系的に分析してみましょう。4 つの異なる予算サイズをテストします:\n",
    "\n",
    "- **1,024 トークン**: 最低限必要な予算\n",
    "- **2,048 トークン**: 中程度の予算\n",
    "- **4,096 トークン**: 十分な予算\n",
    "- **8,192 トークン**: 非常に大きな予算\n",
    "\n",
    "予算サイズごとに、次の項目を測定します:\n",
    "\n",
    "1. **応答時間**: 応答を取得するのにかかる時間\n",
    "2. **トークン使用量**: 使用されたトークンの合計数 (入力 + 出力)\n",
    "3. **コスト**: トークン使用量に基づく推定コスト\n",
    "4. **効率**: 1 秒あたりに処理されるトークン数\n",
    "\n",
    "この分析により、コスト、速度、パフォーマンスのバランスが取れた最適な推論予算を見つけることができます。計算タスクに割り当てる適切な CPU 時間を見つけるようなものと考えてください。CPU 時間が少なすぎると、モデルが問題を効果的に解決するための「思考スペース」が不足する可能性があります。CPU 時間が多すぎると、リソースを無駄にしてしまうことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234a2a2-e0a6-49c8-8dce-0876af497fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different reasoning budgets for the complex problem\n",
    "print(\"Testing different reasoning budgets on the sock drawer problem...\")\n",
    "\n",
    "results = []\n",
    "budgets = [1024, 2048, 4096, 8192, 16384]  # Different budget sizes to test\n",
    "\n",
    "for budget in budgets:\n",
    "    print(f\"\\nTesting with reasoning budget: {budget} tokens\")\n",
    "    response = invoke_claude(\n",
    "        complex_prompt,\n",
    "        enable_reasoning=True,\n",
    "        reasoning_budget=budget,\n",
    "        max_tokens=300\n",
    "    )\n",
    "    \n",
    "    # Extract metrics\n",
    "    metrics = {\n",
    "        'budget': budget,\n",
    "        'time': response.get('_elapsed_time', 0),\n",
    "        'input_tokens': response.get('usage', {}).get('inputTokens', 0),\n",
    "        'output_tokens': response.get('usage', {}).get('outputTokens', 0),\n",
    "        'total_tokens': response.get('usage', {}).get('totalTokens', 0),\n",
    "        'cost': (response.get('usage', {}).get('inputTokens', 0) * 0.000003) + \n",
    "                (response.get('usage', {}).get('outputTokens', 0) * 0.000015)\n",
    "    }\n",
    "    \n",
    "    results.append(metrics)\n",
    "    \n",
    "    # Display brief summary\n",
    "    print(f\"Time: {metrics['time']:.2f}s, Tokens: {metrics['total_tokens']}, Cost: ${metrics['cost']:.5f}\")\n",
    "\n",
    "# Create a DataFrame and display the results\n",
    "performance_df = pd.DataFrame(results)\n",
    "display(performance_df)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(performance_df['budget'], performance_df['time'], marker='o')\n",
    "plt.title('Time vs. Reasoning Budget')\n",
    "plt.xlabel('Reasoning Budget (tokens)')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(performance_df['budget'], performance_df['total_tokens'], marker='o')\n",
    "plt.title('Total Tokens vs. Reasoning Budget')\n",
    "plt.xlabel('Reasoning Budget (tokens)')\n",
    "plt.ylabel('Total Tokens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(performance_df['budget'], performance_df['cost'], marker='o')\n",
    "plt.title('Cost vs. Reasoning Budget')\n",
    "plt.xlabel('Reasoning Budget (tokens)')\n",
    "plt.ylabel('Cost ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "efficiency = performance_df['total_tokens'] / performance_df['time']\n",
    "plt.plot(performance_df['budget'], efficiency, marker='o')\n",
    "plt.title('Efficiency (Tokens/Second) vs. Reasoning Budget')\n",
    "plt.xlabel('Reasoning Budget (tokens)')\n",
    "plt.ylabel('Tokens per Second')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110bcb4-2d13-459d-a1ff-ba9874949bbf",
   "metadata": {},
   "source": [
    "## 6. 拡張思考を使用する場合\n",
    "\n",
    "当社の実験とパフォーマンス分析に基づいて、拡張思考を使用する場合についていくつかの結論を導き出すことができます。\n",
    "\n",
    "### 拡張思考の最適な使用例:\n",
    "\n",
    "1. **複雑な推論タスク**: 数学の問題、論理パズル、および複数ステップの推論は、拡張思考から大きなメリットを得られます。\n",
    "\n",
    "2. **徹底的な分析を必要とする問題**: クロードが多くの可能性やエッジケースを考慮する必要がある場合。\n",
    "\n",
    "3. **精度が重要な場合**: 拡張思考は、推論エラーの可能性を減らすことで、一般的に難しい問題の精度を向上させます。\n",
    "\n",
    "4. **透明性の要件**: クロードの推論プロセスを確認してアプローチを検証する必要がある場合。\n",
    "\n",
    "### 標準モードで十分な場合:\n",
    "\n",
    "1. **単純な事実のクエリ**: 「フランスの首都は?」などの簡単な質問の場合、拡張思考は大きなメリットがなくコストを追加します。\n",
    "\n",
    "2. **クリエイティブなタスク**: クリエイティブなライティング、要約、その他のコンテンツ生成タスクでは、拡張思考からそれほど恩恵を受けられない可能性があります。\n",
    "\n",
    "3. **時間に敏感なアプリケーション**: 応答速度が重要な場合は、標準モードの方が応答が速くなります。\n",
    "\n",
    "4. **コストに敏感なアプリケーション**: 拡張思考によりトークンの使用が増加し、コストも増加します。\n",
    "\n",
    "### 適切な推論予算の見つけ方:\n",
    "\n",
    "理想的な推論予算は、タスクの複雑さによって異なります:\n",
    "\n",
    "- **単純な推論タスク**: 1,024～2,048 トークン\n",
    "- **中程度の複雑さ**: 2,048～4,096 トークン\n",
    "- **複雑な問題**: 4,096～8,192 トークン\n",
    "- **非常に複雑な問題**: 8,192 トークン以上\n",
    "\n",
    "パフォーマンス分析で観察されたように、多くの場合、「スイート スポット」があります:\n",
    "- 予算が小さすぎると、Claude が複雑な問題を解決するのに十分なスペースが得られない可能性があります\n",
    "- あるポイントを超えると、予算が大きくなると収益が減少する一方で、コストとレイテンシが増加します\n",
    "- 効率 (1 秒あたりのトークン数) は、中程度の予算サイズでピークに達し、その後低下する傾向があります\n",
    "\n",
    "パフォーマンス チャートは、このトレードオフを視覚的に示し、特定のユース ケースに最適な予算を決定するのに役立ちます。\n",
    "\n",
    "次のノートブックでは、拡張思考をいつ使用するか、またさまざまなタスク タイプに対して推論予算を最適化する方法を決定するための、より体系的なフレームワークについて説明します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
